{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#dnation-kubernetes-monitoring","title":"dNation Kubernetes Monitoring","text":"<p>See status of your Kubernetes infrastructure and applications at a glance using semaphore (green/orange/red) principle: </p> <p>It is a set of Grafana dashboards and Prometheus alerts written in Jsonnet. This Monitoring also supports multi-cluster monitoring by <code>Thanos</code> and following 3 basic design principles:</p> <ol> <li><code>Intuitive</code> - Green, orange and red colors signaling whether or not your action is needed</li> <li><code>Drill-down</code> - if you want details why something is green, orange or red, just click it</li> <li><code>Relevant information only</code> - provide only metrics relevant for this particular area of interest and drill-down level, side-by-side with logs (experimental feature)</li> </ol> <p>Monitoring targets are:</p> Kubernetes Hosts Applications"},{"location":"#full-installation","title":"Full Installation","text":"<p>In case your current Kubernetes installation doesn't contain Prometheus Operator, Grafana or Loki, please install dNation Kubernetes Monitoring Stack helm chart (recommended).</p>"},{"location":"#dashboards-and-alerts-only-installation","title":"Dashboards and Alerts only Installation","text":"<p>In case your current Kubernetes installation already contains Prometheus Operator, Grafana and Loki, please follow here.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>See the documentation and FAQ for further information.  </p>"},{"location":"#contribution-guidelines","title":"Contribution guidelines","text":"<p>If you want to contribute, please read following:</p> <ol> <li>Contribution Guidelines </li> <li>Code of Conduct </li> <li>How To simplify your local development</li> </ol> <p>We use GitHub issues to manage requests and bugs.</p>"},{"location":"#commercial-support","title":"Commercial support","text":"<p>This project has been developed, maintained and used in production by professionals to simplify their day-to-day monitoring tasks and reduce incident reaction time.</p> <p>Commercial support is available, including 24/7, please contact us.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#v2712-2026-01-07","title":"v2.7.12 (2026-01-07)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix openstack alert #221</li> </ul>"},{"location":"CHANGELOG/#v2711-2025-12-12","title":"v2.7.11 (2025-12-12)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix cluster label in alerts #220</li> </ul>"},{"location":"CHANGELOG/#v2710-2025-12-10","title":"v2.7.10 (2025-12-10)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix expr for Openstack and Ceph #218</li> </ul>"},{"location":"CHANGELOG/#v279-2025-12-04","title":"v2.7.9 (2025-12-04)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add app dashboard - openstack #215</li> </ul>"},{"location":"CHANGELOG/#v278-2025-12-04","title":"v2.7.8 (2025-12-04)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add Ceph app window in cluster overview #217</li> </ul>"},{"location":"CHANGELOG/#v277-2025-11-26","title":"v2.7.7 (2025-11-26)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add dashboard for Ceph monitoring #214</li> </ul>"},{"location":"CHANGELOG/#v276-2025-11-05","title":"v2.7.6 (2025-11-05)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add openstack dashboard #213</li> </ul>"},{"location":"CHANGELOG/#v275-2025-10-31","title":"v2.7.5 (2025-10-31)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Replace seriesToRows with merge(byName) in order to fix single alert #212</li> </ul>"},{"location":"CHANGELOG/#v274-2025-10-07","title":"v2.7.4 (2025-10-07)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#enhancements","title":"Enhancements","text":"<ul> <li>Allow to add common annotations for all resources #201</li> </ul> <p>Merged pull requests:</p> <ul> <li>Add availability panel for each service #211</li> <li>fix: changelog and docs workflows #208</li> </ul>"},{"location":"CHANGELOG/#v273-2025-09-09","title":"v2.7.3 (2025-09-09)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>commonAnnotations added  #207</li> </ul>"},{"location":"CHANGELOG/#v272-2025-05-29","title":"v2.7.2 (2025-05-29)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#v271-2024-12-03","title":"v2.7.1 (2024-12-03)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Port work from scs-kaas-mvp branch to the main branch #195</li> </ul> <p>Merged pull requests:</p> <ul> <li>Fix issue with host-alert panel for grafana 10 #200</li> </ul>"},{"location":"CHANGELOG/#v270-2024-02-14","title":"v2.7.0 (2024-02-14)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Port work from scs-kaas-mvp branch to the main branch #197</li> </ul>"},{"location":"CHANGELOG/#v263-2024-01-29","title":"v2.6.3 (2024-01-29)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add cluster label to alert link annotation #194</li> </ul>"},{"location":"CHANGELOG/#v262-2023-11-21","title":"v2.6.2 (2023-11-21)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Preserve cluster label also for apps alerts #181</li> </ul>"},{"location":"CHANGELOG/#v261-2023-11-21","title":"v2.6.1 (2023-11-21)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix old table panel in alert-overview we are using for Grafana versions 10+ #182</li> </ul>"},{"location":"CHANGELOG/#v260-2023-11-21","title":"v2.6.0 (2023-11-21)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Preserve cluster label for alerts #180</li> </ul>"},{"location":"CHANGELOG/#v254-2023-11-14","title":"v2.5.4 (2023-11-14)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix queries #178</li> </ul>"},{"location":"CHANGELOG/#v253-2023-07-18","title":"v2.5.3 (2023-07-18)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix x and y coordinates of app box overview #170</li> </ul>"},{"location":"CHANGELOG/#v252-2023-06-27","title":"v2.5.2 (2023-06-27)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add ssl-exporter app to main dashboard #169</li> </ul>"},{"location":"CHANGELOG/#v251-2023-06-19","title":"v2.5.1 (2023-06-19)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#enhancements_1","title":"Enhancements","text":"<ul> <li>Add Harbor dashboard #164</li> </ul> <p>Merged pull requests:</p> <ul> <li>Update SSL Exporter dashboard #168</li> </ul>"},{"location":"CHANGELOG/#v250-2023-05-26","title":"v2.5.0 (2023-05-26)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add Harbor dashboard #167</li> </ul>"},{"location":"CHANGELOG/#v240-2023-05-24","title":"v2.4.0 (2023-05-24)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Small comment in values.yaml #166</li> <li>Add support for k8s version 1.24+ #165</li> </ul>"},{"location":"CHANGELOG/#v231-2023-05-09","title":"v2.3.1 (2023-05-09)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix, ssl exporter dashboard #163</li> </ul>"},{"location":"CHANGELOG/#v230-2023-05-04","title":"v2.3.0 (2023-05-04)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add dashboard for ssl-exporter #162</li> </ul>"},{"location":"CHANGELOG/#v222-2023-04-18","title":"v2.2.2 (2023-04-18)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix duplicate series for host monitoring in multicluster setup #161</li> </ul>"},{"location":"CHANGELOG/#v221-2023-04-12","title":"v2.2.1 (2023-04-12)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Bump up monitoring version #160</li> <li>Fix Docs badge #159</li> </ul>"},{"location":"CHANGELOG/#v220-2023-03-24","title":"v2.2.0 (2023-03-24)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Create and fill CHANGELOG.md #83</li> <li>Add Prometheus dashboard #35</li> </ul> <p>Merged pull requests:</p> <ul> <li>Bump up translator version in dependencies #158</li> </ul>"},{"location":"CHANGELOG/#v211-2023-01-26","title":"v2.1.1 (2023-01-26)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Fix generation of docs and pages #157</li> </ul>"},{"location":"CHANGELOG/#v210-2023-01-23","title":"v2.1.0 (2023-01-23)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>V2.1.x #156</li> </ul>"},{"location":"CHANGELOG/#v202-2023-01-19","title":"v2.0.2 (2023-01-19)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Mysql exporter alerts missing job label #148</li> </ul> <p>Merged pull requests:</p> <ul> <li>Added alertgroup label for apps.rules #154</li> </ul>"},{"location":"CHANGELOG/#v200-2022-11-08","title":"v2.0.0 (2022-11-08)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Update dashboards for multi-cluster monitoring #153</li> </ul>"},{"location":"CHANGELOG/#v142-2022-10-11","title":"v1.4.2 (2022-10-11)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Fix <code>Tag branch</code> github action #150</li> </ul> <p>Merged pull requests:</p> <ul> <li>Change ControlPlane template #152</li> <li>Update github-tag-action to 1.39.0 #151</li> </ul>"},{"location":"CHANGELOG/#v141-2022-08-15","title":"v1.4.1 (2022-08-15)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#fixes","title":"Fixes","text":"<ul> <li>Wrong job variable for host monitoring when going directly to dashboard #133</li> </ul> <p>Closed issues:</p> <ul> <li>Add dashboard for websocket server #97</li> <li>Add dashboard for JVM exporter #96</li> <li>Add Loki dashboard #34</li> </ul> <p>Merged pull requests:</p> <ul> <li>Update template values to work with grafana 9 #149</li> <li>Fixed config for kind #142</li> </ul>"},{"location":"CHANGELOG/#v140-2022-02-11","title":"v1.4.0 (2022-02-11)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#fixes_1","title":"Fixes","text":"<ul> <li>Color problem: white value on white background #129</li> <li>Duplicate series error after alertGroup label deletition #117</li> <li>Improve PromQL expressions to resist the label change #115</li> </ul> <p>Closed issues:</p> <ul> <li>Add ci actions to test monitoring installation in latest k8s [releases](https://kubernetes.io/releases/) #130</li> </ul> <p>Merged pull requests:</p> <ul> <li>V1.4.x #139</li> </ul>"},{"location":"CHANGELOG/#v134-2022-01-11","title":"v1.3.4 (2022-01-11)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Update docs - define minimal cpu/mem requirements  needed for successful installation  #131</li> </ul> <p>Merged pull requests:</p> <ul> <li>Fix color problem on Light theme for Used/Total Cores/Ram/Disk #132</li> </ul>"},{"location":"CHANGELOG/#v133-2021-06-22","title":"v1.3.3 (2021-06-22)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Use 'Last (not null)' reducer function in L3 pvc gauge panels #126</li> </ul>"},{"location":"CHANGELOG/#v132-2021-06-21","title":"v1.3.2 (2021-06-21)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#fixes_2","title":"Fixes","text":"<ul> <li>Column sorting in L2 tables doesn't work #123</li> <li>Links in L2 tables have bad variable mapping #121</li> </ul> <p>Merged pull requests:</p> <ul> <li>L2fixes #124</li> </ul>"},{"location":"CHANGELOG/#v131-2021-06-17","title":"v1.3.1 (2021-06-17)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#fixes_3","title":"Fixes","text":"<ul> <li>Missing  hyperlink in MySQL Application Graph - Host Monitoring #120</li> <li>Fix legend in Request duration 99th quantile graph - Api server dashboard #119</li> <li>Fix Job graph expression #116</li> </ul> <p>Closed issues:</p> <ul> <li>MySQL dashboard should have hostname #118</li> <li>L0 expression - If host/cluster is DOWN L0 state panel still shows OK state #112</li> <li>Replace legacy nginx vts metrics #110</li> <li>Split Node Metrics to Master/Nodes #107</li> </ul> <p>Merged pull requests:</p> <ul> <li>Minor graph fixies #122</li> </ul>"},{"location":"CHANGELOG/#v130-2021-06-07","title":"v1.3.0 (2021-06-07)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Investigate and, if necessary, change usedDisk expression #105</li> <li>Host monitoring - improve host monitoring expressions to be resistant in case of IP address miss configuration  #100</li> <li>Improve Nginx VTS dashboard #95</li> <li>Hard coded label alertGroup \"Host\" in PromQL expression #88</li> <li>Add support for KubeVirt VMs #79</li> <li>Visualize Virtual Filesystems Utilization in separate graph #76</li> <li>Re-organize cluster main dashboard  #75</li> </ul> <p>Merged pull requests:</p> <ul> <li>V1.3.x #114</li> <li>Update AWS_doc.md #106</li> <li>Update aws_doc.md #102</li> <li>Rename namespace in AWS-doc.md #101</li> <li>Aws doc #92</li> </ul>"},{"location":"CHANGELOG/#v121-2021-05-13","title":"v1.2.1 (2021-05-13)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>2x increase in CPU usage after redeployment of monitoring #90</li> </ul> <p>Merged pull requests:</p> <ul> <li>Consider null values in stacked graphs as zero #91</li> </ul>"},{"location":"CHANGELOG/#cicd-jsonnet-v103-2021-05-04","title":"cicd-jsonnet-v1.0.3 (2021-05-04)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#v120-2021-05-04","title":"v1.2.0 (2021-05-04)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>In the nginx ingress alert Detailed link is 'var-job=' empty #80</li> <li>Make copyright headers consistent across #71</li> <li>Add dashboards for MySQL/MariaDB #70</li> </ul> <p>Merged pull requests:</p> <ul> <li>V1.2.x #89</li> </ul>"},{"location":"CHANGELOG/#v112-2021-04-21","title":"v1.1.2 (2021-04-21)","text":"<p>Full Changelog</p>"},{"location":"CHANGELOG/#fixes_4","title":"Fixes","text":"<ul> <li>L0 Warning state panel with red color backgroud  #66</li> </ul> <p>Closed issues:</p> <ul> <li>Add template logic to the L3 layers #65</li> <li>Re-Order Columns in L2 dashboards #63</li> <li>Add template logic to the L2 layers #17</li> </ul> <p>Merged pull requests:</p> <ul> <li>Change nginxIngressCertificateExpiry expr to preserve labels #81</li> </ul>"},{"location":"CHANGELOG/#v111-2021-02-25","title":"v1.1.1 (2021-02-25)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Fix Job select in Job Overview L2 dashboard #62</li> <li>Release v1.1.x #57</li> </ul> <p>Merged pull requests:</p> <ul> <li>Fix Job select in Job Overview #64</li> </ul>"},{"location":"CHANGELOG/#v110-2021-02-23","title":"v1.1.0 (2021-02-23)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Dependencies update -  dnation jsonnet translator version #56</li> <li>Update CONTRIBUTING.md file according to the latest versioning rules  #50</li> <li>Annoying <code>Do you want to save your changes?</code> alert even when dashboard has not been changed   #47</li> <li>CI pipeline improvement - follow up issue  #46</li> <li>Update FAQ - Why L2 table item has different background color as corresponding L1 stat panel?  #45</li> <li>Add basic drop-down menu on k8s L2 dashboards #43</li> <li>Add release version badge to the README  #41</li> <li>Update L1 dashboards - rename RPC to GRPC #39</li> <li>Update L1 links in k8s monitoring dashboard #37</li> <li>[Docs] Escape double quotes in expressions #36</li> <li>Add possibility to exclude dashboard from <code>helm upgrade</code> process #33</li> <li>Add template logic to the L0 layer #25</li> <li>Ingress controller dashboard L1 - improve expression #19</li> </ul> <p>Merged pull requests:</p> <ul> <li>V1.1.x #61</li> <li>Escape quotes in docs #53</li> <li>Update contributing #52</li> <li>Lint appVersion always with main branch #49</li> </ul>"},{"location":"CHANGELOG/#v1025-2021-02-05","title":"v1.0.25 (2021-02-05)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Create CI/CD job to check version of monitoring application #30</li> </ul> <p>Merged pull requests:</p> <ul> <li>Fix linting appVersion in ci #44</li> <li>Fix missing escape of '%' in jsonnet #42</li> <li>Add ci check of appVersion #38</li> </ul>"},{"location":"CHANGELOG/#v1024-2021-02-03","title":"v1.0.24 (2021-02-03)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Add hyperlinks to the Alerts table panel and/or messages  #21</li> </ul> <p>Merged pull requests:</p> <ul> <li>Round value of NginxIngressSuccessRateLow alert #40</li> </ul>"},{"location":"CHANGELOG/#v1023-2021-02-03","title":"v1.0.23 (2021-02-03)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Add FAQ - How to interpret displayed monitoring values across layers?  #22</li> <li>Add HOST IP address info to the L3 layer of monitoring #20</li> </ul> <p>Merged pull requests:</p> <ul> <li>Add grafana dashboard link to alerts #32</li> <li>Simplify local development #31</li> </ul>"},{"location":"CHANGELOG/#v1022-2021-01-25","title":"v1.0.22 (2021-01-25)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Add possibility to adjust the monitoring dashboards default directory #18</li> </ul> <p>Merged pull requests:</p> <ul> <li>Add HOST IP address info table to the NodeExporter #29</li> </ul>"},{"location":"CHANGELOG/#v1021-2021-01-25","title":"v1.0.21 (2021-01-25)","text":"<p>Full Changelog</p> <p>Closed issues:</p> <ul> <li>Docs json-&gt;yaml #24</li> <li>Record short video to show the latest monitoring state.   #16</li> </ul> <p>Merged pull requests:</p> <ul> <li>Add option to change grafana directory #28</li> <li>Change docs from json to yaml #26</li> <li>Update README.md #23</li> </ul>"},{"location":"CHANGELOG/#v1020-2021-01-14","title":"v1.0.20 (2021-01-14)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Docs #15</li> </ul>"},{"location":"CHANGELOG/#cicd-jsonnet-v102-2021-01-14","title":"cicd-jsonnet-v1.0.2 (2021-01-14)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Update ci/cd image version to 1.0.2 #14</li> <li>Sync gitlab main #13</li> <li>Fix release.yaml bug #12</li> <li>Update CODE_OF_CONDUCT.md #11</li> <li>Update CODE_OF_CONDUCT.md #10</li> </ul>"},{"location":"CHANGELOG/#v1019-2020-11-13","title":"v1.0.19 (2020-11-13)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Update README.md #9</li> <li>Node filter #8</li> </ul>"},{"location":"CHANGELOG/#cicd-jsonnet-v101-2020-11-11","title":"cicd-jsonnet-v1.0.1 (2020-11-11)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Increase version of packages in docker image #7</li> </ul>"},{"location":"CHANGELOG/#cicd-jsonnet-v100-2020-11-10","title":"cicd-jsonnet-v1.0.0 (2020-11-10)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Create tag when CI/CD jsonnet docker code changes #6</li> </ul>"},{"location":"CHANGELOG/#v1018-2020-10-28","title":"v1.0.18 (2020-10-28)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Notes #4</li> </ul>"},{"location":"CHANGELOG/#v1017-2020-10-27","title":"v1.0.17 (2020-10-27)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Update CDN image urls #3</li> </ul>"},{"location":"CHANGELOG/#v1016-2020-10-26","title":"v1.0.16 (2020-10-26)","text":"<p>Full Changelog</p> <p>Merged pull requests:</p> <ul> <li>Add jsonnet build and lint to the GitHub CI/CD pipeline and update chart version #2</li> <li>Add GitHub CI/CD #1</li> </ul>"},{"location":"CODE_OF_CONDUCT/","title":"dNation Kubernetes Monitoring Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by  Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available  at https://www.contributor-covenant.org/translations.</p>"},{"location":"CONTRIBUTING/","title":"dNation Kubernetes Monitoring Contributing Guidelines","text":"<p>Thank you for considering to contribute to dNation Kubernetes Monitoring project.</p> <p>When contributing to this repository, please first discuss the change you wish to make via issue, email, or by any other method with the owners of this repository before making a change.</p>"},{"location":"CONTRIBUTING/#pull-request-checklist","title":"Pull Request Checklist","text":"<p>Before sending your pull requests, make sure you followed this list.</p> <ul> <li>Read Contributing Guidelines</li> <li>Read Code of Conduct</li> <li>Read Commit Message Convention</li> <li>Read How To simplify your local development</li> <li>Set up the Developer Certificate of Origin (DCO)</li> <li>Include a License at the top of new files</li> <li>Update the Readme with details of changes to the interface</li> <li>In case the pull request would update the version number, please edit the version number in all appropriate   files e.g. Chart.yaml. Read more about our chart versioning policy.</li> <li>Choose appropriate base branch for pull request. Read more about our release policy.</li> <li>You may merge the Pull Request once you have the sign-off of other developer, or if you   don't have the permission to do that, you may request the reviewer to merge it for you</li> </ul>"},{"location":"CONTRIBUTING/#developer-certificate-of-origin-dco","title":"Developer Certificate of Origin (DCO)","text":"<p>The Developer Certificate of Origin (DCO) is a legally binding statement that asserts that you are the creator of your contribution, and that you wish to allow dNation Kubernetes Monitoring project to use your work.</p> <p>Acknowledgement of this permission is done using a sign-off process in Git. The sign-off is a simple line at the end of the explanation for the patch. The text of the DCO is available on developercertificate.org.</p> <p>If you are willing to agree to these terms, you just add a line to every git commit message:</p> <p><code>Signed-off-by: Joe Smith &lt;joe.smith@email.com&gt;</code></p> <p>If you set your <code>user.name</code> and <code>user.email</code> as part of your git configuration, you can sign your commit automatically with <code>git commit -s</code>.</p> <p>Unfortunately, you have to use your real name (i.e., pseudonyms or anonymous contributions cannot be made). This is because the DCO is a legally binding document, granting the dNation Kubernetes Monitoring project to use your work.</p>"},{"location":"CONTRIBUTING/#license-on-the-top-of-file","title":"License on the top of file","text":"<pre><code>/*\n  Copyright 2020 The dNation Kubernetes Monitoring Authors. All Rights Reserved.\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n      http://www.apache.org/licenses/LICENSE-2.0\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License.\n*/\n</code></pre>"},{"location":"CONTRIBUTING/#release-policy","title":"Release policy","text":"<ul> <li>Release branch <code>vMajor.Minor.x</code> (e.g. <code>v1.1.x</code>) - all PRs with new functionality should target this branch</li> <li>PRs with hot-fixes target <code>main</code> branch</li> </ul>"},{"location":"CONTRIBUTING/#chart-versioning-policy","title":"Chart versioning policy","text":"<p>Versioning scheme is SemVer.</p> <ul> <li>version: should increase when changes in chart are made</li> <li>appVersion: should increase when changes in <code>jsonnet/</code> folder are made (when <code>appVersion</code> is increased, <code>version</code> has to be too)</li> <li>version and appVersion in release branch are set to same version as new release will be</li> </ul>"},{"location":"GETTING_STARTED/","title":"Dashboards and Alerts only Installation","text":"<p>Installation on top of an existing monitoring infrastructure (Prometheus Operator, Grafana and Loki are already installed).</p>"},{"location":"GETTING_STARTED/#installation","title":"Installation","text":"<p>Prerequisites * Helm3</p> <p>dNation Kubernetes Monitoring helm chart is hosted in the dNation helm repository. <pre><code># Add dNation helm repository\nhelm repo add dnationcloud https://dnationcloud.github.io/helm-hub/\nhelm repo update\n\n# Install dNation Kubernetes Monitoring\nhelm install dnation-kubernetes-monitoring dnationcloud/dnation-kubernetes-monitoring\n</code></pre></p> <p>Search for <code>Monitoring</code> dashboard. The fun starts here :). If you want to set the <code>Monitoring</code> dashboard as a home dashboard follow here. If you're experiencing issues please read the documentation and FAQ.</p> <p>You should set the external label <code>cluster</code> for your Prometheus instance and this label should be the same, as the one defined in the label field in values.yaml for your cluster monitoring. E.g., if you installed Prometheus via kube-prometheus-stack helm chart: <pre><code>kube-prometheus-stack:\n  prometheus:\n    prometheusSpec:\n      externalLabels:\n        cluster: \"observer-cluster\"\n</code></pre></p>"},{"location":"GETTING_STARTED/#configuration","title":"Configuration","text":"<p>Default values for dNation Kubernetes Monitoring are defined by merging of jsonnet/config.libsonnet and chart/values.yaml files. Full list of possible configuration parameters are listed in the project documentation. All default values can be overridden as in standard helm chart, see examples in helpers directory.</p>"},{"location":"chart/","title":"dNation Kubernetes Monitoring","text":"<p>Please follow instructions described in dNation Kubernetes Monitoring project.</p>"},{"location":"docs/AWS_doc/","title":"AWS","text":""},{"location":"docs/AWS_doc/#get-started-with-dnation-cloud-chart-using-amazon-eks-and-the-aws-marketplace","title":"Get Started With dNation Cloud Chart Using Amazon EKS And The AWS Marketplace","text":""},{"location":"docs/AWS_doc/#introduction","title":"Introduction","text":"<p>Amazon Web Services (AWS) provides a number of different cloud and container services, including the Amazon Elastic Container Service for Kubernetes (EKS), which allows users to quickly and easily create Kubernetes clusters in the cloud. But starting up a cluster is just the beginning: the next step is to deploy applications and monitor them.</p> <p>That\u2019s where this tutorial comes in. It will walk you, step by step, through the process of using the AWS Marketplace to deploy dNation Kubernetes monitoring on a running EKS cluster.</p>"},{"location":"docs/AWS_doc/#overview","title":"Overview","text":"<p>This guide will walk you through the process of deploying and managing applications in an EKS cluster using the AWS Marketplace and Helm. This guide will show you the steps to deploy the dNation Kubernetes Monitoring Helm chart on your EKS cluster with Helm.</p> <p>Here are the steps you\u2019ll follow in this tutorial:</p> <ul> <li>Subscribe to the dNation Kubernetes Monitoring using the AWS Marketplace</li> <li>Deploy the dNation Kubernetes Monitoring Helm chart on EKS through Helm</li> <li>Log in and start using dNation Kubernetes Monitoring</li> </ul> <p>The next sections will walk you through these steps in detail.</p>"},{"location":"docs/AWS_doc/#assumptions-and-prerequisites","title":"Assumptions And Prerequisites","text":"<p>This guide assumes that:</p> <ul> <li>You have an active AWS account. If you don\u2019t have this, create a new account.</li> <li>You have a running EKS cluster with a minimal two nodes with allocatable 11 pods per node, e.g. instances like t2.small or t3.small and higher. And also Helm 3.x, kubectl are installed.</li> </ul>"},{"location":"docs/AWS_doc/#step-1-subscribe-to-the-dnation-kubernetes-monitoring-using-the-aws-marketplace","title":"Step 1: Subscribe To The dNation Kubernetes Monitoring Using The AWS Marketplace","text":"<p>At the end of this step, you will have subscribed to the dNation Kubernetes Monitoring solution in the AWS Marketplace.</p> <p>Follow these steps:</p> <ul> <li>Log in to the AWS Marketplace.</li> </ul> <p></p> <ul> <li>Search for the dNation Kubernetes Monitoring by entering the search term \u201cdNation kubernetes monitoring\u201d in the search bar at the top.</li> <li>Select the dNation Kubernetes Monitoring in the list of search results.</li> <li>On the product detail page, review the details of the solution and click the \u201cContinue to subscribe\u201d button.</li> </ul> <p></p> <ul> <li>On the product subscription page, select \u201cContinue to configuration\u201d as accept the terms and pricing.</li> </ul> <p></p> <ul> <li>On the product configuration page, select delivery method as \u201cContainer\u201d , select Software version and click the \u201cContinue to Launch\u201c.</li> </ul> <p></p> <ul> <li>On the launch page, select \u201cView container image details\u201c and copy the URL to the AWS Marketplace registry.   You will need these details in installation.</li> </ul> <p></p> <ul> <li>Review your configuration, select \u201cDeployment Guide\u201c and follow step-by-step instructions for installing dNation Kubernetes Monitoring.</li> </ul> <p></p>"},{"location":"docs/AWS_doc/#step-2-deploy-dnation-kubernetes-monitoring-helm-chart-on-eks","title":"Step 2: Deploy dNation Kubernetes Monitoring Helm Chart On EKS","text":"<p>At the end of this step, you will have deployed dNation Kubernetes Monitoring on your EKS cluster.</p> <p>The next step is to deploy dNation Kubernetes Monitoring on your EKS cluster using AWS repository, which you obtained in a previous step. The easiest way to do this is with a Helm chart.</p> <p>Follow these steps:</p> <ul> <li> <p>Add dNation helm repository and update it.   <pre><code># Add dNation helm repository\nhelm repo add dnationcloud https://dnationcloud.github.io/helm-hub/\nhelm repo update\n</code></pre></p> </li> <li> <p>It is a good practice to install new packages in a separate namespace, as it is easier to manage it this way. Create a new namespace, for example call it \"monitoring\"   <pre><code>kubectl create namespace monitoring\n</code></pre></p> </li> <li> <p>In case your current Kubernetes installation doesn't contain Prometheus Operator, Grafana or Loki, please install dNation Kubernetes Monitoring Stack helm chart (recommended) with dNation Kubernetes Monitoring Chart   <pre><code># Install dNation Kubernetes Monitoring Stack with dNation Kubernetes Monitoring chart\nhelm upgrade --install dnation-kubernetes-monitoring-stack dnationcloud/dnation-kubernetes-monitoring-stack --namespace monitoring --set dnation-kubernetes-monitoring.dnation-kubernetes-jsonnet-translator.image.repository=709825985650.dkr.ecr.us-east-1.amazonaws.com/dnation/kubernetes-jsonnet-translator --set dnation-kubernetes-monitoring.dnation-kubernetes-jsonnet-translator.image.tag=&lt;image-tag&gt; --version=&lt;helm-chart-version&gt;\n</code></pre>   Example of installation for helm chart version <code>1.1.2</code>:   <pre><code># Install dNation Kubernetes Monitoring Stack with dNation Kubernetes Monitoring chart\nhelm upgrade --install dnation-kubernetes-monitoring-stack dnationcloud/dnation-kubernetes-monitoring-stack --namespace monitoring --set dnation-kubernetes-monitoring.dnation-kubernetes-jsonnet-translator.image.repository=709825985650.dkr.ecr.us-east-1.amazonaws.com/dnation/kubernetes-jsonnet-translator --set dnation-kubernetes-monitoring.dnation-kubernetes-jsonnet-translator.image.tag=0.2.0 --version=1.1.2\n</code></pre></p> </li> <li> <p>If your current Kubernetes installation already contains Prometheus Operator, Grafana and Loki, please follow this   <pre><code># Install dNation Kubernetes Monitoring\nhelm upgrade --install dnation-kubernetes-monitoring dnationcloud/dnation-kubernetes-monitoring --namespace monitoring --set dnation-kubernetes-jsonnet-translator.image.repository=709825985650.dkr.ecr.us-east-1.amazonaws.com/dnation/kubernetes-jsonnet-translator --set dnation-kubernetes-monitoring.dnation-kubernetes-jsonnet-translator.image.tag=&lt;image-tag&gt; --version=&lt;helm-chart-version&gt;\n</code></pre>   Example of installation for helm chart version <code>1.1.2</code>:   <pre><code># Install dNation Kubernetes Monitoring\nhelm upgrade --install dnation-kubernetes-monitoring dnationcloud/dnation-kubernetes-monitoring --namespace monitoring --set dnation-kubernetes-jsonnet-translator.image.repository=709825985650.dkr.ecr.us-east-1.amazonaws.com/dnation/kubernetes-jsonnet-translator --set dnation-kubernetes-monitoring.dnation-kubernetes-jsonnet-translator.image.tag=0.2.0 --version=1.1.2\n</code></pre></p> </li> <li> <p>Check its status by running   <pre><code>kubectl get pods --namespace monitoring \n</code></pre></p> </li> </ul>"},{"location":"docs/AWS_doc/#step-3-log-in-and-start-using-dnation-kubernetes-monitoring","title":"Step 3: Log In And Start Using dNation Kubernetes Monitoring","text":"<p>At the end of this step, you will have logged in to the dNation Kubernetes Monitoring.</p> <p>To log in to the dNation Kubernetes Monitoring dashboard, follow these steps:</p> <ul> <li> <p>Get your 'admin' user password by running   <pre><code>kubectl --namespace monitoring get secret dnation-kubernetes-monitoring-stack-grafana -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n</code></pre></p> </li> <li> <p>Use Port Forwarding if you want to access the Grafana server from outside your cluster   <pre><code>export POD_NAME=$(kubectl get pods --namespace monitoring -l \"app.kubernetes.io/name=grafana,app.kubernetes.io/instance=dnation-kubernetes-monitoring-stack\" -o jsonpath=\"{.items[0].metadata.name}\")\nkubectl --namespace monitoring port-forward $POD_NAME 3000\n</code></pre></p> </li> <li> <p>If you didn't modify the default values the Grafana server is exposed by ClusterIP service and can be accessed via port 80 on the DNS name. Usually at the URL http://DNS/ or if you used Port Forwarding at http://localhost:3000/</p> </li> </ul> <p></p> <ul> <li>Login with the password you obtained at the first bullet point and the username: 'admin', then you should arrive at 'Home' page</li> </ul> <p></p> <ul> <li>Click on the \"Search\" icon on left hand side and search for <code>Monitoring</code> dashboard in the <code>dNation</code> directory and you will see \"L0 layer\", where your cluster and hosts will be displayed. </li> </ul> <p></p> <ul> <li>If you want to see more information about your cluster, just drill down by left-clicking on the state panel. The fun starts here :)</li> </ul> <p></p> <p>If you want to set the <code>Monitoring</code> dashboard as a home dashboard follow here. If you're experiencing issues please read the documentation and FAQ.</p> <p>Happy Monitoring !</p>"},{"location":"docs/AWS_doc/#useful-links","title":"Useful Links","text":"<p>To learn more about the topics discussed in this tutorial, use the links below:</p> <ul> <li>Amazon EKS</li> <li>Kubernetes</li> <li>Helm</li> <li>dNation Kubernetes Monitoring</li> <li>dNation Cloud</li> </ul>"},{"location":"docs/README_DOCS/","title":"Kubernetes Monitoring Documentation","text":""},{"location":"docs/README_DOCS/#generate-documentation","title":"Generate documentation","text":"<p>Prerequisites   - Python3</p> <pre><code>pip3 install -r \"docs/requirements.txt\"\nmake docs-generate\n</code></pre> <p>Afterwards folder <code>docs/site</code> with static website is created. </p>"},{"location":"docs/README_DOCS/#local-development","title":"Local development","text":"<p>Python script docs/generate_md_docs.py is responsible for creating markdown documents  from configuration files.</p> <p>Mkdocs tool is used for generating documentation website from markdown files. Tool comes with built-in dev-server that can be used to preview work on documentation. <pre><code># whole project is copied inside docs/project folder\nrsync -Rr ./ docs/project\ncd docs/project\npython3 docs/generate_md_docs.py\ncd ..\nmkdocs serve\n</code></pre> Mkdocs doesn't have access to files outside <code>docs_dir</code> (in our case <code>docs/project</code>)  and configuration file (<code>mkdocs.yaml</code>) has to be at least one level above <code>docs_dir</code> in filesystem tree.  Therefore whole project has to be copied inside <code>docs/project</code> to allow Mkdocs to access files like <code>chart/README.md</code> or  <code>helpers/FAQ.md</code>.  To see changes at dev-server, files inside <code>docs/project</code> has to be modified. After development is done,  changes has to be copied to <code>kubernetes-monitoring</code> folder and command <code>make docs-generate</code> has to be run.</p> <p>Other option that avoids copying changes is using symlink. <pre><code># symlink to kubernets-monitoring folder is created inside docs folder\nln -s .. docs/project\npython3 docs/generate_md_docs.py\ncd docs\nmkdocs serve --no-livereload\n</code></pre> Disadvantage is unability to use livereload because of 'infinite path' of symlink (<code>docs/project/docs/project/...</code>). Server has to be restarted to reload changes. After development is done, symlink has to be deleted and command <code>make docs-generate</code> run.</p>"},{"location":"docs/README_DOCS/#cicd","title":"CI/CD","text":"<p>Github workflow is used to regenerate documentation and deploy site to branch <code>gh-pages</code> if changes are made inside <code>docs</code> folder, any REAMDE file or in configuration files.</p>"},{"location":"docs/documentation-intro/","title":"Documentation intro","text":""},{"location":"docs/documentation-intro/#dnation-kubernetes-monitoring-docs","title":"dnation Kubernetes Monitoring Docs","text":"<p>This is generated documentation from configuration files of Kubernetes Monitoring. </p> <p>Each configuration parameter can be overriden by providing custom values.yaml during helm installation.</p> <p></p>"},{"location":"docs/documentation/","title":"Docs","text":""},{"location":"docs/documentation/#dnation-kubernetes-monitoring-docs","title":"dnation Kubernetes Monitoring Docs","text":"<p>This is generated documentation from configuration files of Kubernetes Monitoring. </p> <p>Each configuration parameter can be overriden by providing custom values.yaml during helm installation.</p> <p></p> PropertyValueblackboxMonitoring<code>enabled: false </code> clusterMonitoringclusterMonitoring commonAnnotations<code>{} </code> commonLabels<code>{} </code> dnation-kubernetes-jsonnet-translator<code>enabled: true </code> fullnameOverride<code>\"\"</code> grafanaDashboardsgrafanaDashboards hostMonitoringhostMonitoring kaasMonitoringkaasMonitoring nameOverride<code>\"\"</code> namespaceOverride<code>\"\"</code> prometheusRulesprometheusRules templatestemplates testbedMonitoring<code>enabled: false </code> <p></p>"},{"location":"docs/documentation/#clustermonitoring","title":"clusterMonitoring","text":"PropertyValueclusters<code>- apps: []   description: Kubernetes cluster monitoring   label: observer-cluster   name: K8sCluster </code> enabled<code>true</code>"},{"location":"docs/documentation/#grafanadashboards","title":"grafanaDashboards","text":"PropertyValuecolorcolor constantsconstants dataLinkCommonArgs<code>\"var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to\"</code> dataLinkCommonArgsBlackbox<code>\"var-datasource=$datasource&amp;var-target=$target&amp;from=$__from&amp;to=$__to\"</code> dataLinkCommonArgsNoCluster<code>\"var-datasource=$datasource&amp;from=$__from&amp;to=$__to\"</code> editable<code>true</code> enable<code>true</code> idsids isLoki<code>true</code> labelGrafana<code>grafana_dashboard: '1' </code> labelJsonnet<code>grafana_dashboard_jsonnet: '1' </code> refresh<code>\"10s\"</code> selectorsselectors severityColorsseverityColors tagstags templateRefresh<code>\"time\"</code> templateSort<code>5</code> time_from<code>\"now-5m\"</code> tooltip<code>\"shared_crosshair\"</code>"},{"location":"docs/documentation/#color","title":"color","text":"PropertyValueblack<code>\"#000000\"</code> blue<code>\"#5794f2\"</code> gray<code>\"#858187\"</code> green<code>\"#56a64b\"</code> lightblue<code>\"#8ab8ff\"</code> orange<code>\"#ff780a\"</code> pink<code>\"#fce2de\"</code> purple<code>\"#a352cc\"</code> red<code>\"#e02f44\"</code> white<code>\"#ffffff\"</code> yellow<code>\"#fade2a\"</code>"},{"location":"docs/documentation/#constants","title":"constants","text":"PropertyValueinfinity<code>100000000000000005366162204393472</code> maxWarnings<code>10000</code>"},{"location":"docs/documentation/#ids","title":"ids","text":"PropertyValuealertClusterOverview<code>\"alertclusteroverview\"</code> alertHostOverview<code>\"alerthostoverview\"</code> alertKaasOverview<code>\"alertkaasoverview\"</code> alertTestbedOverview<code>\"alerttestbedoverview\"</code> alertVMOverview<code>\"alertvmoverview\"</code> apache<code>\"apache\"</code> apiServer<code>\"apiserver\"</code> autoscaler<code>\"autoscaler\"</code> cAdvisor<code>\"cadvisor\"</code> ceph<code>\"ceph\"</code> containerDetail<code>\"containerdetail\"</code> containerOverview<code>\"containeroverview\"</code> controllerManager<code>\"controllermanager\"</code> cpuNamespaceOverview<code>\"cpunamespaceoverview\"</code> cpuOverview<code>\"cpuoverview\"</code> daemonSetOverview<code>\"daemonsetoverview\"</code> deploymentOverview<code>\"deploymentoverview\"</code> diskOverview<code>\"diskoverview\"</code> etcd<code>\"etcd\"</code> harbor<code>\"harbor\"</code> hostMonitoring<code>\"hostmonitoring\"</code> javaActuator<code>\"javaactuator\"</code> jobOverview<code>\"joboverview\"</code> jvm<code>\"jvm\"</code> k8sMonitoring<code>\"k8smonitoring\"</code> kaasL1Monitoring<code>\"kaasl1monitoring\"</code> kaasMonitoring<code>\"kaas-monitoring\"</code> kubelet<code>\"kubelet\"</code> lokiDistributed<code>\"loki-distributed\"</code> memoryNamespaceOverview<code>\"memorynamespaceoverview\"</code> memoryOverview<code>\"memoryoverview\"</code> monitoring<code>\"monitoring\"</code> mysqlExporter<code>\"mysqlexporter\"</code> networkNamespaceOverview<code>\"networknamespaceoverview\"</code> networkOverview<code>\"networkoverview\"</code> nginxIngress<code>\"nginxingress\"</code> nginxNrpe<code>\"nginxnrpe\"</code> nginxVts<code>\"nginxvts\"</code> nginxVtsEnhanced<code>\"nginxvtsenhanced\"</code> nginxVtsEnhancedLegacy<code>\"nginxvtsenhancedlegacy\"</code> nginxVtsLegacy<code>\"nginxvtslegacy\"</code> nodeExporter<code>\"nodeexporter\"</code> nodeOverview<code>\"nodeoverview\"</code> openstack<code>\"openstack\"</code> persistentVolumes<code>\"persistentvolumes\"</code> phpFpm<code>\"phpfpm\"</code> podOverview<code>\"podoverview\"</code> postfix<code>\"postfix\"</code> prometheus<code>\"prometheus\"</code> proxy<code>\"proxy\"</code> pvcOverview<code>\"pvcoverview\"</code> pythonFlask<code>\"pythonflask\"</code> rabbitmq<code>\"rabbitmq\"</code> scheduler<code>\"scheduler\"</code> sslExporter<code>\"ssl-exporter\"</code> statefulSet<code>\"statefulset\"</code> statefulSetOverview<code>\"statefulsetoverview\"</code> testbed<code>\"testbed\"</code> vmMonitoring<code>\"vmmonitoring\"</code> websocket<code>\"websocket\"</code>"},{"location":"docs/documentation/#selectors","title":"selectors","text":"PropertyValueapiServer<code>\"job=\\\"apiserver\\\"\"</code> controllerManager<code>\"job=\\\"kube-controller-manager\\\"\"</code> etcd<code>\"job=\\\"kube-etcd\\\"\"</code> kubelet<code>\"job=\\\"kubelet\\\"\"</code> proxy<code>\"job=\\\"kube-proxy\\\"\"</code> scheduler<code>\"job=\\\"kube-scheduler\\\"\"</code>"},{"location":"docs/documentation/#severitycolors","title":"severityColors","text":"PropertyValuecritical<code>\"red\"</code> default<code>\"green\"</code> invalid<code>\"black\"</code> warning<code>\"orange\"</code>"},{"location":"docs/documentation/#tags","title":"tags","text":"PropertyValuek8sApps<code>- k8s - app - L1 </code> k8sAppsMain<code>- k8s - app - L0 </code> k8sContainer<code>- k8s - container - L3 </code> k8sHostsMain<code>- k8s - host - L1 </code> k8sMonitoring<code>- k8s - monitoring - L1 </code> k8sMonitoringMain<code>- k8s - cluster - host - L0 </code> k8sNodeExporter<code>- k8s - nodeexporter - L3 </code> k8sOverview<code>- k8s - overview - L2 </code> k8sPVC<code>- k8s - pvc - L3 </code> k8sStatefulSet<code>- k8s - statefulset - L3 </code> k8sSystem<code>- k8s - system - L2 </code> k8sVMs<code>- k8s - vm - L2 </code> kaasMonitoring<code>- kaas - monitoring - L1 </code> kaasMonitoringMain<code>- kaas - cluster - L0 </code> testbed<code>- testbed - L0 </code> testbedAlert<code>- testbed - L1 </code>"},{"location":"docs/documentation/#hostmonitoring","title":"hostMonitoring","text":"PropertyValueenabled<code>false</code> hosts<code>[] </code>"},{"location":"docs/documentation/#kaasmonitoring","title":"kaasMonitoring","text":"PropertyValueclusters<code>- description: KaaS monitoring   name: KaasCluster </code> enabled<code>false</code>"},{"location":"docs/documentation/#prometheusrules","title":"prometheusRules","text":"PropertyValuealertGroupCluster<code>\"Cluster\"</code> alertGroupClusterApp<code>\"ClusterApp\"</code> alertGroupClusterVM<code>\"ClusterVM\"</code> alertGroupClusterVMApp<code>\"ClusterVMApp\"</code> alertGroupHost<code>\"Host\"</code> alertGroupHostApp<code>\"HostApp\"</code> alertInterval<code>\"5m\"</code> alertNamePrefix<code>\"KubernetesMonitoring\"</code> enable<code>true</code> labelJsonnet<code>prometheus_rule_jsonnet: '1' </code> labelPrometheus<code>prometheus_rule: '1' </code>"},{"location":"docs/documentation/#templates","title":"templates","text":"PropertyValueL0L0 L1L1 L2L2 RecordRules<code>- expr: node_uname_info{job=~\"node-exporter\"} and on(nodename) label_replace(kube_node_role{role=~\"control-plane\"},     \"nodename\", \"$1\", \"node\", \"(.+)\")   record: master_uname_info - expr: node_uname_info{job=~\"node-exporter\"} unless on(nodename) label_replace(kube_node_role{role=~\"control-plane\"},     \"nodename\", \"$1\", \"node\", \"(.+)\")   record: worker_uname_info </code> commonThresholdscommonThresholds templateBasestemplateBases"},{"location":"docs/documentation/#l0","title":"L0","text":"PropertyValueblackboxblackbox hosthost k8sk8s kaaskaas testbedtestbed"},{"location":"docs/documentation/#blackbox","title":"blackbox","text":"PropertyValuemainmain <p> main </p> PropertyValuepanel<code>expr: probe_success{target=~\"%(target)s\", endpoint=\"http\"} graphMode: none gridPos:   h: 3   w: 4 mappings: - from: -1   text: '-'   to: -1   type: 2   value: '' - from: 0   text: Critical   to: 0   type: 2   value: '' - from: 1   text: OK   to: 1   type: 2   value: '' thresholds:   critical: 1   lowest: 0   operator: &lt; unit: none </code> <p></p>"},{"location":"docs/documentation/#host","title":"host","text":"PropertyValuemainmain <p> main </p> PropertyValuepanel<code>expr: ((sum(up{job=~\"%(job)s\"}) or on() vector(0)) == bool 0) * (-1) + sum(ALERTS{alertname!=\"Watchdog\",   alertstate=\"firing\", severity=\"warning\", job=~\"%(job)s\", alertgroup=~\"%(groupHost)s|%(groupHostApp)s\"}   OR on() vector(0)) + sum(ALERTS{alertname!=\"Watchdog\", alertstate=\"firing\", severity=\"critical\",   job=~\"%(job)s\", alertgroup=~\"%(groupHost)s|%(groupHostApp)s\"} OR on() vector(0))   * %(maxWarnings)d graphMode: none gridPos:   h: 3   w: 4 mappings: - from: -1   text: Down   to: -1   type: 2   value: '' - from: 0   text: OK   to: 0   type: 2   value: '' - from: 1   text: Warning   to: 9999   type: 2   value: '' - from: 10000   text: Critical   to: 100000000000000005366162204393472   type: 2   value: '' thresholds:   critical: 10000   lowest: 0   operator: '&gt;='   warning: 1 unit: none </code> <p></p>"},{"location":"docs/documentation/#k8s","title":"k8s","text":"PropertyValuemainmain <p> main </p> PropertyValuepanel<code>expr: ((sum(up{job=~\"node-exporter\", cluster=\"%(cluster)s\"}) or on() vector(0)) ==   bool 0) * (-1) + sum(ALERTS{alertname!=\"Watchdog\", cluster=\"%(cluster)s\", alertstate=\"firing\",   severity=\"warning\", alertgroup=~\"%(groupCluster)s|%(groupApp)s\"} OR on() vector(0))   + sum(ALERTS{alertname!=\"Watchdog\", cluster=\"%(cluster)s\", alertstate=\"firing\",   severity=\"critical\", alertgroup=~\"%(groupCluster)s|%(groupApp)s\"} OR on() vector(0))   * %(maxWarnings)d graphMode: none gridPos:   h: 3   w: 4 mappings: - from: -1   text: Down   to: -1   type: 2   value: '' - from: 0   text: OK   to: 0   type: 2   value: '' - from: 1   text: Warning   to: 9999   type: 2   value: '' - from: 10000   text: Critical   to: 100000000000000005366162204393472   type: 2   value: '' thresholds:   critical: 10000   lowest: 0   operator: '&gt;='   warning: 1 unit: none </code> <p></p>"},{"location":"docs/documentation/#kaas","title":"kaas","text":"PropertyValuemainmain <p> main </p> PropertyValuepanel<code>expr: ((sum(kaas{cluster=\"%(cluster)s\"} unless up{job=~\"node-exporter\", cluster=\"%(cluster)s\"})   or on() vector(0)) == bool 0) * (-1) + ((sum(kaas{cluster=\"%(cluster)s\"}) or on()   vector(0)) == bool 0) * (-1) + sum(ALERTS{alertname!=\"Watchdog\", cluster=\"%(cluster)s\",   alertstate=\"firing\", severity=\"warning\", alertgroup=~\"%(groupCluster)s|%(groupApp)s\"}   OR on() vector(0)) + sum(ALERTS{alertname!=\"Watchdog\", cluster=\"%(cluster)s\", alertstate=\"firing\",   severity=\"critical\", alertgroup=~\"%(groupCluster)s|%(groupApp)s\"} OR on() vector(0))   * %(maxWarnings)d graphMode: none gridPos:   h: 3   w: 4 mappings: - from: -2   text: '-'   to: -2   type: 2   value: '' - from: -1   text: Down   to: -1   type: 2   value: '' - from: 0   text: OK   to: 0   type: 2   value: '' - from: 1   text: Warning   to: 9999   type: 2   value: '' - from: 10000   text: Critical   to: 100000000000000005366162204393472   type: 2   value: '' thresholds:   critical: 10000   lowest: 0   operator: '&gt;='   warning: 1 unit: none </code> <p></p>"},{"location":"docs/documentation/#testbed","title":"testbed","text":"PropertyValuemainmain <p> main </p> PropertyValuepanel<code>expr: ((sum(up{infrastructure=\"testbed\"}) or on() vector(0)) == bool 0) * (-1) + sum(ALERTS{alertname!=\"Watchdog\",   infrastructure=\"testbed\", alertstate=\"firing\", severity=\"warning\"} OR on() vector(0))   + sum(ALERTS{alertname!=\"Watchdog\", infrastructure=\"testbed\", alertstate=\"firing\",   severity=\"critical\"} OR on() vector(0)) * %(maxWarnings)d graphMode: none gridPos:   h: 3   w: 4 mappings: - from: -1   text: Down   to: -1   type: 2   value: '' - from: 0   text: OK   to: 0   type: 2   value: '' - from: 1   text: Warning   to: 9999   type: 2   value: '' - from: 10000   text: Critical   to: 100000000000000005366162204393472   type: 2   value: '' thresholds:   critical: 10000   lowest: 0   operator: '&gt;='   warning: 1 unit: none </code> <p></p>"},{"location":"docs/documentation/#l1","title":"L1","text":"PropertyValuehosthost hostAppshostApps k8sk8s k8sAppsk8sApps vmvm vmAppsvmApps"},{"location":"docs/documentation/#host_1","title":"host","text":"PropertyValueoverallNetworkErrorsoverallNetworkErrors overallUtilizationCPUoverallUtilizationCPU overallUtilizationDiskoverallUtilizationDisk overallUtilizationRAMoverallUtilizationRAM targetDowntargetDown totalCorestotalCores totalDisktotalDisk totalRAMtotalRAM usedCoresusedCores usedDiskusedDisk usedRAMusedRAM <p> overallNetworkErrors </p> PropertyValuealert<code>customLables:   alertgroup: Host expr: sum(rate(node_network_transmit_errs_total{job=~\"%s\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info) )   by (job, nodename) + sum(rate(node_network_receive_errs_total{job=~\"%s\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info) ) by (job,   nodename) linkGetParams: var-instance={{ $labels.nodename }} message: 'Host {{ $labels.nodename }}: High Overall Network Errors Count {{ $value   }}%' name: HostNetworkOverallErrorsHigh thresholds:   critical: 15   operator: '&gt;='   warning: 10 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: sum(rate(node_network_transmit_errs_total{job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info) )   by (job, nodename) + sum(rate(node_network_receive_errs_total{job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info) ) by (job,   nodename) gridPos:   x: 18   y: 6 thresholds:   critical: 15   operator: '&gt;='   warning: 10 title: Overall Errors unit: pps </code> <p></p> <p> overallUtilizationCPU </p> PropertyValuealert<code>customLables:   alertgroup: Host expr: round((1 - (avg(irate(node_cpu_seconds_total{job=~\"%s\", mode=\"idle\"}[5m]) *   on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) by (job,   nodename) )) * 100) linkGetParams: var-instance={{ $labels.nodename }} message: 'Host {{ $labels.nodename }}: High CPU Overall Utilization {{ $value }}%' name: HostCPUOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: avg(round((1 - (avg(irate(node_cpu_seconds_total{job=~\"$job\", mode=\"idle\"}[5m])   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) by (job,   nodename) )) * 100)) gridPos:   x: 0   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization </code> <p></p> <p> overallUtilizationDisk </p> PropertyValuealert<code>customLables:   alertgroup: Host expr: round((sum(node_filesystem_size_bytes{job=~\"%s\"} * on(instance, job, cluster,   pod) group_left(nodename) (node_uname_info)) by (job, nodename, device) - sum(node_filesystem_free_bytes{job=~\"%s\"}   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) by (job,   nodename, device)) / ((sum(node_filesystem_size_bytes{job=~\"%s\"} * on(instance,   job, cluster, pod) group_left(nodename) (node_uname_info)) by (job, nodename, device)   - sum(node_filesystem_free_bytes{job=~\"%s\"} * on(instance, job, cluster, pod) group_left(nodename)   (node_uname_info)) by (job, nodename, device)) + sum(node_filesystem_avail_bytes{job=~\"%s\"}   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) by (job,   nodename, device)) * 100 &gt; 0) linkGetParams: var-instance={{ $labels.nodename }} message: 'Host {{ $labels.nodename }}: High Disk Overall Utilization {{ $value }}%' name: HostDiskOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: max(round((sum(node_filesystem_size_bytes{job=~\"$job\"} * on(instance, job, cluster,   pod) group_left(nodename) (node_uname_info)) by (job, nodename, device) - sum(node_filesystem_free_bytes{job=~\"$job\"}   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) by (job,   nodename, device)) / ((sum(node_filesystem_size_bytes{job=~\"$job\"} * on(instance,   job, cluster, pod) group_left(nodename) (node_uname_info)) by (job, nodename, device)   - sum(node_filesystem_free_bytes{job=~\"$job\"} * on(instance, job, cluster, pod)   group_left(nodename) (node_uname_info)) by (job, nodename, device)) + sum(node_filesystem_avail_bytes{job=~\"$job\"}   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) by (job,   nodename, device)) * 100 &gt; 0)) gridPos:   x: 12   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> overallUtilizationRAM </p> PropertyValuealert<code>customLables:   alertgroup: Host expr: round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"%s\"}   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) / sum   by (job, nodename, cluster) (node_memory_MemTotal_bytes{job=~\"%s\"} * on(instance,   job, cluster, pod) group_left(nodename) (node_uname_info))) * 100) linkGetParams: var-instance={{ $labels.nodename }} message: 'Host {{ $labels.nodename }}: High RAM Overall Utilization {{ $value }}%' name: HostRAMOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: avg(round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"$job\"}   * on(instance, job, cluster, pod) group_left(nodename) (node_uname_info)) / sum   by (job, nodename, cluster) (node_memory_MemTotal_bytes{job=~\"$job\"} * on(instance,   job, cluster, pod) group_left(nodename) (node_uname_info))) * 100)) gridPos:   x: 6   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> targetDown </p> PropertyValuealert<code>customLables:   alertgroup: Host expr: 100 * (count by(job, namespace, service) (up{job=~\"%s\"} == 0) / count by(job,   namespace, service) (up{job=~\"%s\"})) message: '{{ printf \"%.4g\" $value }}% of the {{ $labels.job }}/{{ $labels.service   }} targets in {{ $labels.namespace }} namespace are down.' name: HostTargetDown thresholds:   critical: 90   operator: '&gt;='   warning: 10 </code> panel<code>null</code> <p></p> <p> totalCores </p> PropertyValuepanel<code>colorMode: value expr: count(node_cpu_seconds_total{job=~\"$job\", mode=\"system\"}) graphMode: none gridPos:   h: 2   w: 3   x: 3   y: 9 thresholds:   color: '#858187'   value: title: Total Cores unit: none </code> <p></p> <p> totalDisk </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{job=~\"$job\"}) graphMode: none gridPos:   h: 2   w: 3   x: 15   y: 9 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> totalRAM </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{job=~\"$job\"}) graphMode: none gridPos:   h: 2   w: 3   x: 9   y: 9 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> usedCores </p> PropertyValuepanel<code>colorMode: value expr: (1 - (avg(irate(node_cpu_seconds_total{job=~\"$job\", mode=\"idle\"}[5m])))) * count(node_cpu_seconds_total{job=~\"$job\",   mode=\"system\"}) graphMode: none gridPos:   h: 2   w: 3   x: 0   y: 9 thresholds:   color: '#858187'   value: title: Used Cores unit: none </code> <p></p> <p> usedDisk </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{job=~\"$job\"}) - sum(node_filesystem_free_bytes{job=~\"$job\"}) graphMode: none gridPos:   h: 2   w: 3   x: 12   y: 9 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p> <p> usedRAM </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{job=~\"$job\"}) * (((1 - sum(node_memory_MemAvailable_bytes{job=~\"$job\"})   / sum(node_memory_MemTotal_bytes{job=~\"$job\"})))) graphMode: none gridPos:   h: 2   w: 3   x: 6   y: 9 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p>"},{"location":"docs/documentation/#hostapps","title":"hostApps","text":"PropertyValueapacheapache autoscalerautoscaler cAdvisorcAdvisor cephceph genericAppgenericApp harborharbor javaActuatorjavaActuator jvmjvm lokiDistributedlokiDistributed mysqlExportermysqlExporter nginxIngressnginxIngress nginxIngressCertificateExpirynginxIngressCertificateExpiry nginxNrpenginxNrpe nginxVtsnginxVts nginxVtsEnhancednginxVtsEnhanced nginxVtsEnhancedLegacynginxVtsEnhancedLegacy nginxVtsLegacynginxVtsLegacy openstackopenstack phpFpmphpFpm postfixpostfix prometheusprometheus pythonFlaskpythonFlask rabbitmqrabbitmq sslExportersslExporter websocketwebsocket <p> apache </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> autoscaler </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster) (autoscaler_healthy{job=~\".+\"}) / sum by (job, cluster)   (autoscaler_instances{job=~\".+\"}) * 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Autoscaler Health Low {{ $value }}%' name: HostAppAutoscalerHealthLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- autoscaler </code> panel<code>expr: (sum by (job) (autoscaler_healthy{cluster=\"$cluster\", %(job)s}) / sum by (job)   (autoscaler_instances{cluster=\"$cluster\", %(job)s}) * 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> cAdvisor </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> ceph </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: ceph_health_status{job=~\".+\"} linkGetParams: var-cluster={{ $externalLabels.cluster }} message: 'HostApp Ceph cluster is UNHEALTHY, on cluster : {{ $externalLabels.cluster   }}' name: HostAppCephHealthStatus thresholds:   critical: 2   operator: '&gt;='   warning: 1 </code> default<code>false</code> linkTo<code>- ceph </code> panel<code>expr: ceph_health_status{cluster=\"$cluster\", %(job)s} gridPos:   w: 4 mappings: - text: HEALTHY   type: 1   value: 0 - text: WARNING   type: 1   value: 1 - text: ERROR   type: 1   value: 2 thresholds:   critical: 2   lowest: 0   operator: '&gt;='   warning: 1 </code> <p></p> <p> genericApp </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>description: GenericApp template. Used when application monitoring is requested but   appropriate template was not found. expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 gridPos:   w: 4 thresholds:   critical: 95   operator: &lt;   warning: 99 </code> <p></p> <p> harbor </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: harbor_up{job=~\".+\"} linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Harbor component \"{{ $labels.component }}\" is   down' name: HostAppHarborComponentDown thresholds:   critical: 0   operator: ==   warning: 0 </code> default<code>false</code> linkTo<code>- harbor </code> panel<code>expr: (sum(harbor_up{cluster=\"$cluster\", %(job)s}) / count(harbor_up{cluster=\"$cluster\",   %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> javaActuator </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster) (jvm_memory_used_bytes{job=~\".+\", area=\"heap\"})*100/sum  by   (job, cluster) (jvm_memory_max_bytes{job=~\".+\", area=\"nonheap\"}) &gt; sum  by (job,   cluster) (jvm_memory_used_bytes{job=~\".+\", area=\"nonheap\"})*100/sum  by (job, cluster)   (jvm_memory_max_bytes{job=~\".+\", area=\"heap\"}) or (sum  by (job, cluster) (jvm_memory_used_bytes{job=~\".+\",   area=\"nonheap\"})*100)/sum by (job, cluster) (jvm_memory_max_bytes{job=~\".+\", area=\"heap\"})) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Java Actuator Heap High {{ $value }}%' name: HostAppJavaActuatorHeapHigh thresholds:   critical: 90   lowest: 0   operator: '&gt;='   warning: 75 </code> default<code>false</code> linkTo<code>- javaactuator </code> panel<code>expr: (sum by (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"})*100/sum  by   (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"}) &gt; sum  by   (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"})*100/sum  by   (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"}) or (sum  by   (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"})*100)/sum   by (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"})) OR on()   vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 90   lowest: 0   operator: '&gt;='   warning: 75 </code> <p></p> <p> jvm </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> lokiDistributed </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> mysqlExporter </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> nginxIngress </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: ((sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\", status!~\"[4-5].*\"}[5m]))   / sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\"}[5m]))   * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\"}[5m]))   + 100)) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Nginx Ingress Success Rate (non-4|5xx responses)   Low {{ printf \"%.0f\" $value }}%' name: HostAppNginxIngressSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxingress </code> panel<code>expr: ((sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\", %(job)s,   status!~\"[4-5].*\"}[5m])) / sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\",   %(job)s}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100)) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxIngressCertificateExpiry </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: bottomk(1, nginx_ingress_controller_ssl_expire_time_seconds{job=~\".+\"} - time())   / 60 / 60 / 24 linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Nginx Ingress Certificate Expiry in {{ printf   \"%.2f\" $value }} days' name: HostAppNginxIngressCertificateExpiry thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 8 </code> default<code>false</code> linkTo<code>- nginxingress </code> panel<code>dataLinks: - title: Detail   url:      /d/nginxingress?var-job=%(job)s&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to decimals: 0 expr: bottomk(1, nginx_ingress_controller_ssl_expire_time_seconds{cluster=\"$cluster\",   %(job)s} - time()) OR on() vector(-100000000000000005366162204393472) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -100000000000000005366162204393472 thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 691200 unit: s </code> <p></p> <p> nginxNrpe </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> nginxVts </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: HostAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvts </code> panel<code>expr: (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\", %(job)s,   code!~\"[4-5].*\", code!=\"total\"}[5m])) / sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsEnhanced </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: HostAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtsenhanced </code> panel<code>expr: (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\", %(job)s,   code!~\"[4-5].*\", code!=\"total\"}[5m])) / sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsEnhancedLegacy </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: HostAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtsenhancedlegacy </code> panel<code>expr: (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\", %(job)s, code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsLegacy </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: HostAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtslegacy </code> panel<code>expr: (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\", %(job)s, code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> openstack </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: min by (cluster, job) ({__name__=~\"openstack_.*_up\", job=~\".+\"}) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp OpenStack cluster health is CRITICAL, on cluster : {{ $externalLabels.cluster   }}' name: HostAppOpenStackHealthStatus thresholds:   critical: 0   operator: ==   warning: 10000 </code> default<code>false</code> linkTo<code>- openstack </code> panel<code>expr: min({__name__=~\"openstack_.*_up\", %(job)s, cluster=~\"$cluster\"}) OR vector(-1) gridPos:   w: 4 mappings: - text: OK   type: 1   value: 1 - text: OFFLINE   type: 1   value: -1 - text: CRITICAL   type: 1   value: 0 thresholds:   critical: 1   lowest: 0   operator: &lt; </code> <p></p> <p> phpFpm </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> postfix </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster) (postfix_size{job=~\".+\"})) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} mappings: - text: '-'   type: 1   value: -1 message: 'HostApp {{ $labels.job }}: Postfix Queue Size High {{ $value }}%' name: HostAppPostfixQueueSizeHigh thresholds:   critical: 10   lowest: 0   operator: '&gt;='   warning: 5 </code> default<code>false</code> linkTo<code>- postfix </code> panel<code>expr: (sum by (job) (postfix_size{cluster=\"$cluster\", %(job)s})) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 10   lowest: 0   operator: '&gt;='   warning: 5 unit: mailq </code> <p></p> <p> prometheus </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> pythonFlask </p> PropertyValuealert<code>customLables:   alertgroup: HostApp expr: (sum by (job, cluster)    (rate(flask_http_request_duration_seconds_count{job=~\".+\",status!~\"[4-5].*\"}[5m]))   / sum by (job, cluster) (rate(flask_http_request_duration_seconds_count{job=~\".+\"}[5m]))   * 100) &gt; 0 OR (sum by (job, cluster) (rate(flask_http_request_duration_seconds_count{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'HostApp {{ $labels.job }}: Python Flask Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: HostAppPythonFlaskSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- pythonflask </code> panel<code>expr: (sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s,status!~\"[4-5].*\"}[5m])) / sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> rabbitmq </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> sslExporter </p> PropertyValuealert<code>{} </code> default<code>false</code> linkTo<code>- ssl-exporter </code> panel<code>decimals: 0 expr: bottomk(1,ssl_cert_not_after{cluster=\"$cluster\"}-time() OR ssl_file_cert_not_after{cluster=\"$cluster\"}-time()   OR ssl_kubeconfig_cert_not_after{cluster=\"$cluster\"}-time() OR ssl_kubernetes_cert_not_after{cluster=\"$cluster\"}-time()) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -100000000000000005366162204393472 thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 691200 unit: s </code> <p></p> <p> websocket </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p>"},{"location":"docs/documentation/#k8s_1","title":"k8s","text":"PropertyValueapiServerHealthapiServerHealth controllerManagerHealthcontrollerManagerHealth daemonSetsHealthdaemonSetsHealth deploymentsHealthdeploymentsHealth etcdHealthetcdHealth kubeletHealthkubeletHealth mostUtilizedMasterNodeCPUmostUtilizedMasterNodeCPU mostUtilizedMasterNodeDiskmostUtilizedMasterNodeDisk mostUtilizedMasterNodeNetworkErrorsmostUtilizedMasterNodeNetworkErrors mostUtilizedMasterNodeRAMmostUtilizedMasterNodeRAM mostUtilizedPVCmostUtilizedPVC mostUtilizedWorkerNodeCPUmostUtilizedWorkerNodeCPU mostUtilizedWorkerNodeDiskmostUtilizedWorkerNodeDisk mostUtilizedWorkerNodeNetworkErrorsmostUtilizedWorkerNodeNetworkErrors mostUtilizedWorkerNodeRAMmostUtilizedWorkerNodeRAM nodeHealthnodeHealth overallMasterNodesNetworkErrorsoverallMasterNodesNetworkErrors overallUtilizationMasterNodesCPUoverallUtilizationMasterNodesCPU overallUtilizationMasterNodesDiskoverallUtilizationMasterNodesDisk overallUtilizationMasterNodesRAMoverallUtilizationMasterNodesRAM overallUtilizationWorkerNodesCPUoverallUtilizationWorkerNodesCPU overallUtilizationWorkerNodesDiskoverallUtilizationWorkerNodesDisk overallUtilizationWorkerNodesRAMoverallUtilizationWorkerNodesRAM overallWorkerNodesNetworkErrorsoverallWorkerNodesNetworkErrors proxyHealthproxyHealth pvcBoundpvcBound runningContainersrunningContainers runningPodsrunningPods runningStatefulSetsrunningStatefulSets schedulerHealthschedulerHealth succeededJobssucceededJobs targetDowntargetDown totalCoresMasterNodestotalCoresMasterNodes totalCoresWorkerNodestotalCoresWorkerNodes totalDiskMasterNodestotalDiskMasterNodes totalDiskWorkerNodestotalDiskWorkerNodes totalRAMMasterNodestotalRAMMasterNodes totalRAMWorkerNodestotalRAMWorkerNodes usedCoresMasterNodesusedCoresMasterNodes usedCoresWorkerNodesusedCoresWorkerNodes usedDiskMasterNodesusedDiskMasterNodes usedDiskWorkerNodesusedDiskWorkerNodes usedRAMMasterNodesusedRAMMasterNodes usedRAMWorkerNodesusedRAMWorkerNodes <p> apiServerHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: (sum(up{job=\"apiserver\"}) by (cluster) / count(up{job=\"apiserver\"}) by (cluster))   * 100 linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Api Server Health Low {{ $value }}% name: ClusterApiServerHealthLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- apiserver </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: (sum(up{cluster=\"$cluster\", job=\"apiserver\"}) / count(up{cluster=\"$cluster\",   job=\"apiserver\"})) * 100 OR on() vector(-1) gridPos:   w: 4   x: 0   y: 5 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: API Server </code> <p></p> <p> controllerManagerHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: (sum(up{job=\"kube-controller-manager\"}) by (cluster) / count(up{job=\"kube-controller-manager\"})   by (cluster)) * 100 linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Controller Manager Health Low {{ $value }}% name: ClusterControllerManagerHealthLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- controllermanager </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: (sum(up{cluster=\"$cluster\", job=\"kube-controller-manager\"}) / count(up{cluster=\"$cluster\",   job=\"kube-controller-manager\"})) * 100 OR on() vector(-1) gridPos:   w: 4   x: 4   y: 5 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: Controller Manager </code> <p></p> <p> daemonSetsHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((sum(kube_daemonset_status_updated_number_scheduled OR kube_daemonset_updated_number_scheduled)   by (cluster) + sum(kube_daemonset_status_number_available) by (cluster)) / (2 *   sum(kube_daemonset_status_desired_number_scheduled) by (cluster)) * 100) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: DaemonSets Health Low {{ $value }}% name: RunningDaemonSetsHealthLow thresholds:   critical: 95   operator: &lt;   warning: 99 </code> linkTo<code>- daemonSetOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: round((sum(kube_daemonset_status_updated_number_scheduled{cluster=\"$cluster\"}   OR kube_daemonset_updated_number_scheduled{cluster=\"$cluster\"}) + sum(kube_daemonset_status_number_available{cluster=\"$cluster\"}))   / (2 * sum(kube_daemonset_status_desired_number_scheduled{cluster=\"$cluster\"}))   * 100) gridPos:   x: 6   y: 12 thresholds:   critical: 95   operator: &lt;   warning: 99 title: DaemonSets Health </code> <p></p> <p> deploymentsHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((sum(kube_deployment_status_replicas_updated) by (cluster) + sum(kube_deployment_status_replicas_available)   by (cluster)) / (2 * sum(kube_deployment_status_replicas) by (cluster)) * 100) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Running Deployments Health Low {{ $value }}% name: RunningDeploymentsHealthLow thresholds:   critical: 95   operator: &lt;   warning: 99 </code> linkTo<code>- deploymentOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: round((sum(kube_deployment_status_replicas_updated{cluster=\"$cluster\"}) + sum(kube_deployment_status_replicas_available{cluster=\"$cluster\"}))   / (2 * sum(kube_deployment_status_replicas{cluster=\"$cluster\"})) * 100) gridPos:   x: 0   y: 12 thresholds:   critical: 95   operator: &lt;   warning: 99 title: Deployments Health </code> <p></p> <p> etcdHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: (sum(up{job=\"kube-etcd\"}) by (cluster) / count(up{job=\"kube-etcd\"}) by (cluster))   * 100 linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Etcd Health Low {{ $value }}% name: ClusterEtcdHealthLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- etcd </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: (sum(up{cluster=\"$cluster\", job=\"kube-etcd\"}) / count(up{cluster=\"$cluster\",   job=\"kube-etcd\"})) * 100 OR on() vector(-1) gridPos:   w: 4   x: 8   y: 5 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: Etcd </code> <p></p> <p> kubeletHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: (sum(up{job=\"kubelet\", metrics_path=\"/metrics\"}) by (cluster) / count(up{job=\"kubelet\",   metrics_path=\"/metrics\"}) by (cluster)) * 100 linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Kubelet Health Low {{ $value }}% name: ClusterKubeletHealthLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- kubelet </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: (sum(up{cluster=\"$cluster\", job=\"kubelet\", metrics_path=\"/metrics\"}) / count(up{cluster=\"$cluster\",   job=\"kubelet\", metrics_path=\"/metrics\"})) * 100 OR on() vector(-1) gridPos:   w: 4   x: 12   y: 5 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: Kubelet </code> <p></p> <p> mostUtilizedMasterNodeCPU </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((1 - (avg(irate(node_cpu_seconds_total{job=~\"node-exporter\", mode=\"idle\"}[5m])   * on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename,   cluster) )) * 100) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Master Node {{ $labels.nodename }}: High CPU Utilization {{ $value   }}%' name: ClusterMasterNodeCPUUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/cpuoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/cpunamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: max(round((1 - (avg(irate(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\",   mode=\"idle\"}[5m]) * on(instance, pod) group_left(nodename) (master_uname_info))   by (job, nodename) )) * 100)) gridPos:   w: 3   x: 3   y: 17 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized Node </code> <p></p> <p> mostUtilizedMasterNodeDisk </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((sum(node_filesystem_size_bytes{job=~\"node-exporter\"} * on(instance, pod)   group_left(nodename) (master_uname_info)) by (job, nodename, device, cluster) -   sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (master_uname_info)) by (job, nodename, device, cluster)) / ((sum(node_filesystem_size_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename,   device, cluster) - sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance,   pod) group_left(nodename) (master_uname_info)) by (job, nodename, device, cluster))   + sum(node_filesystem_avail_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (master_uname_info)) by (job, nodename, device, cluster)) * 100) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Master Node {{ $labels.nodename }}: High Disk Utilization {{ $value   }}%' name: ClusterMasterNodeDiskUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/diskoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: max(round((sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\"} *   on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename, device)   - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (master_uname_info)) by (job, nodename, device)) / ((sum(node_filesystem_size_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (master_uname_info)) by (job,   nodename, device) - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename,   device)) + sum(node_filesystem_avail_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (master_uname_info)) by (job, nodename, device)) * 100)) gridPos:   w: 3   x: 15   y: 17 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized Node  <p></p> <p> mostUtilizedMasterNodeNetworkErrors </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: sum(rate(node_network_transmit_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, pod) group_left(nodename) (master_uname_info) ) by (job, nodename,   cluster) + sum(rate(node_network_receive_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (master_uname_info) ) by (job, nodename,   cluster) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Master Node {{ $labels.nodename }}: High Network Errors Count {{   $value }}%' name: ClusterMasterNodeNetworkErrorsHigh thresholds:   critical: 15   operator: '&gt;='   warning: 10 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/networkoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/networknamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: max(sum(rate(node_network_transmit_errs_total{cluster=\"$cluster\", job=~\"$job\",   device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"} [5m]) * on(instance,   pod) group_left(nodename) (master_uname_info) ) by (job, nodename) + sum(rate(node_network_receive_errs_total{cluster=\"$cluster\",   job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (master_uname_info) ) by (job, nodename)) gridPos:   w: 3   x: 21   y: 17 thresholds:   critical: 15   operator: '&gt;='   warning: 10 title: Most Affected Node unit: pps </code> <p></p> <p> mostUtilizedMasterNodeRAM </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (master_uname_info)) / sum by (job, nodename,   cluster) (node_memory_MemTotal_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (master_uname_info))) * 100) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Master Node {{ $labels.nodename }}: High RAM Utilization {{ $value   }}%' name: ClusterMasterNodesRAMUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/memoryoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/memorynamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: max(round((1 - sum by (job, nodename) (node_memory_MemAvailable_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (master_uname_info)) / sum   by (job, nodename) (node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (master_uname_info))) * 100)) gridPos:   w: 3   x: 9   y: 17 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized Node  <p></p> <p> mostUtilizedPVC </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: sum(((kubelet_volume_stats_capacity_bytes - kubelet_volume_stats_available_bytes)   / kubelet_volume_stats_capacity_bytes) * 100) by (persistentvolumeclaim, cluster) linkGetParams: var-pvc={{ $labels.persistentvolumeclaim }}&amp;var-cluster={{ $externalLabels.cluster   }} message: '\"{{ $labels.persistentvolumeclaim }}\": High PVC Utilization {{ $value }}%' name: PVCUtilizationHigh thresholds:   critical: 97   lowest: 0   operator: '&gt;='   warning: 85 </code> linkTo<code>- pvcOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: max(sum(((kubelet_volume_stats_capacity_bytes{cluster=\"$cluster\"} - kubelet_volume_stats_available_bytes{cluster=\"$cluster\"})   / kubelet_volume_stats_capacity_bytes{cluster=\"$cluster\"}) * 100) by (persistentvolumeclaim))   OR on() vector(-1) gridPos:   w: 3   x: 21   y: 12 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 97   lowest: 0   operator: '&gt;='   warning: 85 title: Most Utilized PVC </code> <p></p> <p> mostUtilizedWorkerNodeCPU </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((1 - (avg(irate(node_cpu_seconds_total{job=~\"node-exporter\", mode=\"idle\"}[5m])   * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename,   cluster) )) * 100) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Worker Node {{ $labels.nodename }}: High CPU Utilization {{ $value   }}%' name: ClusterWorkerNodeCPUUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/cpuoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/cpunamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: max(round((1 - (avg(irate(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\",   mode=\"idle\"}[5m]) * on(instance, pod) group_left(nodename) (worker_uname_info))   by (job, nodename) )) * 100)) gridPos:   w: 3   x: 3   y: 24 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized Node </code> <p></p> <p> mostUtilizedWorkerNodeDisk </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((sum(node_filesystem_size_bytes{job=~\"node-exporter\"} * on(instance, pod)   group_left(nodename) (worker_uname_info)) by (job, nodename, device, cluster) -   sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (worker_uname_info)) by (job, nodename, device, cluster)) / ((sum(node_filesystem_size_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename,   device, cluster) - sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance,   pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device, cluster))   + sum(node_filesystem_avail_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (worker_uname_info)) by (job, nodename, device, cluster)) * 100) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Worker Node {{ $labels.nodename }}: High Disk Utilization {{ $value   }}%' name: ClusterWorkerNodeDiskUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/diskoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: max(round((sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\"} *   on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device)   - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device)) / ((sum(node_filesystem_size_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job,   nodename, device) - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename,   device)) + sum(node_filesystem_avail_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device)) * 100)) gridPos:   w: 3   x: 15   y: 24 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized Node  <p></p> <p> mostUtilizedWorkerNodeNetworkErrors </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: sum(rate(node_network_transmit_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, pod) group_left(nodename) (worker_uname_info) ) by (job, nodename,   cluster) + sum(rate(node_network_receive_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (worker_uname_info) ) by (job, nodename,   cluster) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Worker Node {{ $labels.nodename }}: High Network Errors Count {{   $value }}%' name: ClusterWorkerNodeNetworkErrorsHigh thresholds:   critical: 15   operator: '&gt;='   warning: 10 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/networkoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/networknamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: max(sum(rate(node_network_transmit_errs_total{cluster=\"$cluster\", job=~\"$job\",   device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"} [5m]) * on(instance,   pod) group_left(nodename) (worker_uname_info) ) by (job, nodename) + sum(rate(node_network_receive_errs_total{cluster=\"$cluster\",   job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (worker_uname_info) ) by (job, nodename)) gridPos:   w: 3   x: 21   y: 24 thresholds:   critical: 15   operator: '&gt;='   warning: 10 title: Most Affected Node unit: pps </code> <p></p> <p> mostUtilizedWorkerNodeRAM </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (worker_uname_info)) / sum by (job, nodename,   cluster) (node_memory_MemTotal_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (worker_uname_info))) * 100) linkGetParams: var-instance={{ $labels.nodename }}&amp;var-cluster={{ $externalLabels.cluster   }} message: 'Cluster Worker Node {{ $labels.nodename }}: High RAM Utilization {{ $value   }}%' name: ClusterWorkerNodesRAMUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/memoryoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/memorynamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: max(round((1 - sum by (job, nodename) (node_memory_MemAvailable_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (worker_uname_info)) / sum   by (job, nodename) (node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (worker_uname_info))) * 100)) gridPos:   w: 3   x: 9   y: 24 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized Node  <p></p> <p> nodeHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round(sum(kube_node_info) by (cluster) / (sum(kube_node_info) by (cluster) +   sum(kube_node_spec_unschedulable) by (cluster) +    sum(kube_node_status_condition{condition=~\"DiskPressure|MemoryPressure|PIDPressure\",   status=~\"true|unknown\"}) by (cluster) + sum(kube_node_status_condition{condition=\"Ready\",   status=~\"false|unknown\"}) by (cluster)) * 100) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Nodes Health Low {{ $value }}% name: NodesHealthLow thresholds:   critical: 95   operator: &lt;   warning: 99 </code> linkTo<code>- nodeOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: round(sum(kube_node_info{cluster=\"$cluster\"}) / (sum(kube_node_info{cluster=\"$cluster\"})   + sum(kube_node_spec_unschedulable{cluster=\"$cluster\"}) + sum(kube_node_status_condition{cluster=\"$cluster\",   condition=~\"DiskPressure|MemoryPressure|PIDPressure\", status=~\"true|unknown\"})  +   sum(kube_node_status_condition{cluster=\"$cluster\", condition=\"Ready\", status=~\"false|unknown\"})   ) * 100) gridPos:   x: 0   y: 9 thresholds:   critical: 95   operator: &lt;   warning: 99 title: Nodes Health </code> <p></p> <p> overallMasterNodesNetworkErrors </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: sum(sum(rate(node_network_transmit_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, pod) group_left(nodename) (master_uname_info) ) by (job, nodename,   cluster) + sum(rate(node_network_receive_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (master_uname_info) ) by (job, nodename,   cluster)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Master Nodes High Overall Network Errors Count {{ $value }}% name: ClusterMasterNodesNetworkOverallErrorsHigh thresholds:   critical: 15   operator: '&gt;='   warning: 10 </code> linkTo<code>- networkPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/networknamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: sum(sum(rate(node_network_transmit_errs_total{cluster=\"$cluster\", job=~\"$job\",   device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"} [5m]) * on(instance,   pod) group_left(nodename) (master_uname_info) ) by (job, nodename) + sum(rate(node_network_receive_errs_total{cluster=\"$cluster\",   job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (master_uname_info) ) by (job, nodename)) gridPos:   w: 3   x: 18   y: 17 thresholds:   critical: 15   operator: '&gt;='   warning: 10 title: Overall Errors unit: pps </code> <p></p> <p> overallUtilizationMasterNodesCPU </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: avg(round((1 - (avg(irate(node_cpu_seconds_total{job=~\"node-exporter\", mode=\"idle\"}[5m])   * on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename,   cluster) )) * 100)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Master Nodes High CPU Overall Utilization {{ $value }}% name: ClusterMasterNodesCPUOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- cpuPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/cpunamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: avg(round((1 - (avg(irate(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\",   mode=\"idle\"}[5m]) * on(instance, pod) group_left(nodename) (master_uname_info))   by (job, nodename) )) * 100)) gridPos:   w: 3   x: 0   y: 17 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization </code> <p></p> <p> overallUtilizationMasterNodesDisk </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: avg(round((sum(node_filesystem_size_bytes{job=~\"node-exporter\"} * on(instance,   pod) group_left(nodename) (master_uname_info)) by (job, nodename, device, cluster)   - sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (master_uname_info)) by (job, nodename, device, cluster)) / ((sum(node_filesystem_size_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename,   device, cluster) - sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance,   pod) group_left(nodename) (master_uname_info)) by (job, nodename, device, cluster))   + sum(node_filesystem_avail_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (master_uname_info)) by (job, nodename, device, cluster)) * 100 &gt; 0)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Master Nodes High Disk Overall Utilization {{ $value }}% name: ClusterMasterNodesDiskOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- diskPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: avg(round((sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\"} *   on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename, device)   - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (master_uname_info)) by (job, nodename, device)) / ((sum(node_filesystem_size_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (master_uname_info)) by (job,   nodename, device) - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (master_uname_info)) by (job, nodename,   device)) + sum(node_filesystem_avail_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (master_uname_info)) by (job, nodename, device)) * 100   &gt; 0)) gridPos:   w: 3   x: 12   y: 17 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> overallUtilizationMasterNodesRAM </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: avg(round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (master_uname_info)) / sum by (job, nodename,   cluster) (node_memory_MemTotal_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (master_uname_info))) * 100)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Master Nodes High RAM Overall Utilization {{ $value }}% name: ClusterMasterNodesRAMOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- memoryPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/memorynamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: avg(round((1 - sum by (job, nodename) (node_memory_MemAvailable_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (master_uname_info)) / sum   by (job, nodename) (node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (master_uname_info))) * 100)) gridPos:   w: 3   x: 6   y: 17 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> overallUtilizationWorkerNodesCPU </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: avg(round((1 - (avg(irate(node_cpu_seconds_total{job=~\"node-exporter\", mode=\"idle\"}[5m])   * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename,   cluster) )) * 100)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Worker Nodes High CPU Overall Utilization {{ $value }}% name: ClusterWorkerNodesCPUOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- cpuPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/cpunamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: avg(round((1 - (avg(irate(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\",   mode=\"idle\"}[5m]) * on(instance, pod) group_left(nodename) (worker_uname_info))   by (job, nodename) )) * 100)) gridPos:   w: 3   x: 0   y: 24 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization </code> <p></p> <p> overallUtilizationWorkerNodesDisk </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: avg(round((sum(node_filesystem_size_bytes{job=~\"node-exporter\"} * on(instance,   pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device, cluster)   - sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (worker_uname_info)) by (job, nodename, device, cluster)) / ((sum(node_filesystem_size_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename,   device, cluster) - sum(node_filesystem_free_bytes{job=~\"node-exporter\"} * on(instance,   pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device, cluster))   + sum(node_filesystem_avail_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (worker_uname_info)) by (job, nodename, device, cluster)) * 100 &gt; 0)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Worker Nodes High Disk Overall Utilization {{ $value }}% name: ClusterWorkerNodesDiskOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- diskPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: avg(round((sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\"} *   on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device)   - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device)) / ((sum(node_filesystem_size_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job,   nodename, device) - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (worker_uname_info)) by (job, nodename,   device)) + sum(node_filesystem_avail_bytes{cluster=\"$cluster\", job=~\"$job\"} * on(instance,   pod) group_left(nodename) (worker_uname_info)) by (job, nodename, device)) * 100   &gt; 0)) gridPos:   w: 3   x: 12   y: 24 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> overallUtilizationWorkerNodesRAM </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: avg(round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"node-exporter\"}   * on(instance, pod) group_left(nodename) (worker_uname_info)) / sum by (job, nodename,   cluster) (node_memory_MemTotal_bytes{job=~\"node-exporter\"} * on(instance, pod) group_left(nodename)   (worker_uname_info))) * 100)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Worker Nodes High RAM Overall Utilization {{ $value }}% name: ClusterWorkerNodesRAMOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- memoryPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/memorynamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: avg(round((1 - sum by (job, nodename) (node_memory_MemAvailable_bytes{cluster=\"$cluster\",   job=~\"$job\"} * on(instance, pod) group_left(nodename) (worker_uname_info)) / sum   by (job, nodename) (node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\"}   * on(instance, pod) group_left(nodename) (worker_uname_info))) * 100)) gridPos:   w: 3   x: 6   y: 24 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> overallWorkerNodesNetworkErrors </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: sum(sum(rate(node_network_transmit_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, pod) group_left(nodename) (worker_uname_info) ) by (job, nodename,   cluster) + sum(rate(node_network_receive_errs_total{job=~\"node-exporter\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (worker_uname_info) ) by (job, nodename,   cluster)) by (cluster) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Worker Nodes High Overall Network Errors Count {{ $value }}% name: ClusterWorkerNodesNetworkOverallErrorsHigh thresholds:   critical: 15   operator: '&gt;='   warning: 10 </code> linkTo<code>- networkPerNodePolystat </code> panel<code>dataLinks: - title: System Overview   url:      /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to&amp;var-instance=All - title: K8s Overview   url:      /d/networknamespaceoverview?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: sum(sum(rate(node_network_transmit_errs_total{cluster=\"$cluster\", job=~\"$job\",   device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"} [5m]) * on(instance,   pod) group_left(nodename) (worker_uname_info) ) by (job, nodename) + sum(rate(node_network_receive_errs_total{cluster=\"$cluster\",   job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, pod) group_left(nodename) (worker_uname_info) ) by (job, nodename)) gridPos:   w: 3   x: 18   y: 24 thresholds:   critical: 15   operator: '&gt;='   warning: 10 title: Overall Errors unit: pps </code> <p></p> <p> proxyHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: (sum(up{job=\"kube-proxy\"}) by (cluster) / count(up{job=\"kube-proxy\"}) by (cluster))   * 100 linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Proxy Health Low {{ $value }}% name: ClusterProxyHealthLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- proxy </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: (sum(up{cluster=\"$cluster\", job=\"kube-proxy\"}) / count(up{cluster=\"$cluster\",   job=\"kube-proxy\"})) * 100 OR on() vector(-1) gridPos:   w: 4   x: 16   y: 5 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: Proxy </code> <p></p> <p> pvcBound </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: \"round(sum(kube_persistentvolumeclaim_status_phase{phase=\\\"Bound\\\"}) by (cluster)   / (\\nsum(kube_persistentvolumeclaim_status_phase{phase=\\\"Bound\\\"}) by (cluster)   + sum(kube_persistentvolumeclaim_status_phase{phase=\\\"Pending\\\"}) by (cluster) +\\n\\   sum(kube_persistentvolumeclaim_status_phase{phase=\\\"Lost\\\"}) by (cluster)\\n) * 100)\" linkGetParams: var-cluster={{ $externalLabels.cluster }} message: PVC Bound Rate Low {{ $value }}% name: PVCBoundRateLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- pvcOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: \"round(sum(kube_persistentvolumeclaim_status_phase{cluster=\\\"$cluster\\\", phase=\\\"\\   Bound\\\"}) / (\\nsum(kube_persistentvolumeclaim_status_phase{cluster=\\\"$cluster\\\"   , phase=\\\"Bound\\\"}) + sum(kube_persistentvolumeclaim_status_phase{cluster=\\\"$cluster\\\"\\   , phase=\\\"Pending\\\"}) +\\nsum(kube_persistentvolumeclaim_status_phase{cluster=\\\"\\   $cluster\\\", phase=\\\"Lost\\\"})\\n) * 100) OR on() vector(-1)\" gridPos:   w: 3   x: 18   y: 12 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: PVC Bound </code> <p></p> <p> runningContainers </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round(sum(kube_pod_container_status_running) by (cluster) / (sum(kube_pod_container_status_running)   by (cluster) + (count(kube_pod_container_status_terminated) by (cluster) - count(kube_pod_container_status_terminated   unless ignoring(reason) kube_pod_container_status_terminated_reason{reason!=\"Completed\"})   by (cluster)) + sum(kube_pod_container_status_waiting) by (cluster)) * 100) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Running Containers Health Low {{ $value }}% name: RunningContainersHealthLow thresholds:   critical: 95   operator: &lt;   warning: 99 </code> linkTo<code>- containerOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: round(sum(kube_pod_container_status_running{cluster=\"$cluster\"}) / (sum(kube_pod_container_status_running{cluster=\"$cluster\"})   + (sum(kube_pod_container_status_terminated_reason{cluster=\"$cluster\", reason!=\"Completed\"})   OR vector(0)) + sum(kube_pod_container_status_waiting{cluster=\"$cluster\"})) * 100) gridPos:   x: 12   y: 12 thresholds:   critical: 95   operator: &lt;   warning: 99 title: Running Containers </code> <p></p> <p> runningPods </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round(sum(kube_pod_status_phase{phase=\"Running\"}) by (cluster) / (sum(kube_pod_status_phase{phase=\"Running\"})   by (cluster) + sum(kube_pod_status_phase{phase=\"Pending\"}) by (cluster) + sum(kube_pod_status_phase{phase=\"Failed\"})   by (cluster) + sum(kube_pod_status_phase{phase=\"Unknown\"}) by (cluster)) * 100) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Pods Health Low {{ $value }}% name: RunningPodsHealthLow thresholds:   critical: 95   operator: &lt;   warning: 99 </code> linkTo<code>- podOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: round(sum(kube_pod_status_phase{cluster=\"$cluster\", phase=\"Running\"}) / (sum(kube_pod_status_phase{cluster=\"$cluster\",   phase=\"Running\"}) + sum(kube_pod_status_phase{cluster=\"$cluster\", phase=\"Pending\"})   + sum(kube_pod_status_phase{cluster=\"$cluster\", phase=\"Failed\"}) + sum(kube_pod_status_phase{cluster=\"$cluster\",   phase=\"Unknown\"})) * 100) gridPos:   x: 12   y: 9 thresholds:   critical: 95   operator: &lt;   warning: 99 title: Running Pods </code> <p></p> <p> runningStatefulSets </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round(sum(kube_statefulset_status_replicas_ready) by (cluster) / sum(kube_statefulset_status_replicas)   by (cluster) * 100) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: StatefulSets Health Low {{ $value }}% name: RunningStatefulSetsHealthLow thresholds:   critical: 95   operator: &lt;   warning: 99 </code> linkTo<code>- statefulSetOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: round(sum(kube_statefulset_status_replicas_ready{cluster=\"$cluster\"}) / sum(kube_statefulset_status_replicas{cluster=\"$cluster\"})   * 100) gridPos:   x: 6   y: 9 thresholds:   critical: 95   operator: &lt;   warning: 99 title: Running StatefulSets </code> <p></p> <p> schedulerHealth </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: (sum(up{job=\"kube-scheduler\"}) by (cluster) / count(up{job=\"kube-scheduler\"})   by (cluster)) * 100 linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Cluster Scheduler Health Low {{ $value }}% name: ClusterSchedulerHealthLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- scheduler </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: (sum(up{cluster=\"$cluster\", job=\"kube-scheduler\"}) / count(up{cluster=\"$cluster\",   job=\"kube-scheduler\"})) * 100 OR on() vector(-1) gridPos:   w: 4   x: 20   y: 5 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: Scheduler </code> <p></p> <p> succeededJobs </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: round(sum(kube_job_status_succeeded) by (cluster) / (sum(kube_job_status_succeeded)   by (cluster) + sum(kube_job_status_failed) by (cluster)) * 100) linkGetParams: var-cluster={{ $externalLabels.cluster }} message: Succeeded Jobs Rate Low {{ $value }}% name: SucceededJobsRateLow thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> linkTo<code>- jobOverviewTable </code> panel<code>dataLinks: - title: K8s Overview   url: /d/{}?var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: round(sum(kube_job_status_succeeded{cluster=\"$cluster\"}) / (sum(kube_job_status_succeeded{cluster=\"$cluster\"})   + sum(kube_job_status_failed{cluster=\"$cluster\"})) * 100) OR on() vector(-1) gridPos:   x: 18   y: 9 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 title: Succeeded Jobs </code> <p></p> <p> targetDown </p> PropertyValuealert<code>customLables:   alertgroup: Cluster expr: 100 * (count by(job, namespace, service, cluster) (up{pod!~\"virt-launcher.*|\"}   == 0) / count by(job, namespace, service, cluster) (up{pod!~\"virt-launcher.*|\"})) message: '{{ printf \"%.4g\" $value }}% of the {{ $labels.job }}/{{ $labels.service   }} targets in {{ $labels.namespace }} namespace are down.' name: ClusterTargetDown thresholds:   critical: 90   operator: '&gt;='   warning: 10 </code> panel<code>null</code> <p></p> <p> totalCoresMasterNodes </p> PropertyValuepanel<code>colorMode: value expr: count(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\", mode=\"system\",   instance=~\"$masterInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 3   y: 20 thresholds:   color: '#858187'   value: title: Total Cores unit: none </code> <p></p> <p> totalCoresWorkerNodes </p> PropertyValuepanel<code>colorMode: value expr: count(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\", mode=\"system\",   instance=~\"$workerInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 3   y: 27 thresholds:   color: '#858187'   value: title: Total Cores unit: none </code> <p></p> <p> totalDiskMasterNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$masterInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 15   y: 20 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> totalDiskWorkerNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$workerInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 15   y: 27 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> totalRAMMasterNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$masterInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 9   y: 20 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> totalRAMWorkerNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$workerInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 9   y: 27 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> usedCoresMasterNodes </p> PropertyValuepanel<code>colorMode: value expr: (1 - (avg(irate(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\", mode=\"idle\",   instance=~\"$masterInstance\"}[5m])))) * count(node_cpu_seconds_total{cluster=\"$cluster\",   job=~\"$job\", mode=\"system\", instance=~\"$masterInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 0   y: 20 thresholds:   color: '#858187'   value: title: Used Cores unit: none </code> <p></p> <p> usedCoresWorkerNodes </p> PropertyValuepanel<code>colorMode: value expr: (1 - (avg(irate(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\", mode=\"idle\",   instance=~\"$workerInstance\"}[5m])))) * count(node_cpu_seconds_total{cluster=\"$cluster\",   job=~\"$job\", mode=\"system\", instance=~\"$workerInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 0   y: 27 thresholds:   color: '#858187'   value: title: Used Cores unit: none </code> <p></p> <p> usedDiskMasterNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$masterInstance\"})   - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$masterInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 12   y: 20 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p> <p> usedDiskWorkerNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$workerInstance\"})   - sum(node_filesystem_free_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$workerInstance\"}) graphMode: none gridPos:   h: 2   w: 3   x: 12   y: 27 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p> <p> usedRAMMasterNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$masterInstance\"})   * (((1 - sum(node_memory_MemAvailable_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$masterInstance\"})   / sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$masterInstance\"})))) graphMode: none gridPos:   h: 2   w: 3   x: 6   y: 20 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p> <p> usedRAMWorkerNodes </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$workerInstance\"})   * (((1 - sum(node_memory_MemAvailable_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$workerInstance\"})   / sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\", instance=~\"$workerInstance\"})))) graphMode: none gridPos:   h: 2   w: 3   x: 6   y: 27 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p>"},{"location":"docs/documentation/#k8sapps","title":"k8sApps","text":"PropertyValueapacheapache autoscalerautoscaler cAdvisorcAdvisor cephceph genericAppgenericApp harborharbor javaActuatorjavaActuator jvmjvm lokiDistributedlokiDistributed mysqlExportermysqlExporter nginxIngressnginxIngress nginxIngressCertificateExpirynginxIngressCertificateExpiry nginxNrpenginxNrpe nginxVtsnginxVts nginxVtsEnhancednginxVtsEnhanced nginxVtsEnhancedLegacynginxVtsEnhancedLegacy nginxVtsLegacynginxVtsLegacy openstackopenstack phpFpmphpFpm postfixpostfix prometheusprometheus pythonFlaskpythonFlask rabbitmqrabbitmq sslExportersslExporter websocketwebsocket <p> apache </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> autoscaler </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster) (autoscaler_healthy{job=~\".+\"}) / sum by (job, cluster)   (autoscaler_instances{job=~\".+\"}) * 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Autoscaler Health Low {{ $value }}%' name: ClusterAppAutoscalerHealthLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- autoscaler </code> panel<code>expr: (sum by (job) (autoscaler_healthy{cluster=\"$cluster\", %(job)s}) / sum by (job)   (autoscaler_instances{cluster=\"$cluster\", %(job)s}) * 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> cAdvisor </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> ceph </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: ceph_health_status{job=~\".+\"} linkGetParams: var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp Ceph cluster is UNHEALTHY, on cluster : {{ $externalLabels.cluster   }}' name: ClusterAppCephHealthStatus thresholds:   critical: 2   operator: '&gt;='   warning: 1 </code> default<code>false</code> linkTo<code>- ceph </code> panel<code>expr: ceph_health_status{cluster=\"$cluster\", %(job)s} gridPos:   w: 4 mappings: - text: HEALTHY   type: 1   value: 0 - text: WARNING   type: 1   value: 1 - text: ERROR   type: 1   value: 2 thresholds:   critical: 2   lowest: 0   operator: '&gt;='   warning: 1 </code> <p></p> <p> genericApp </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>description: GenericApp template. Used when application monitoring is requested but   appropriate template was not found. expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 gridPos:   w: 4 thresholds:   critical: 95   operator: &lt;   warning: 99 </code> <p></p> <p> harbor </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: harbor_up{job=~\".+\"} linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Harbor component \"{{ $labels.component }}\"   is down' name: ClusterAppHarborComponentDown thresholds:   critical: 0   operator: ==   warning: 0 </code> default<code>false</code> linkTo<code>- harbor </code> panel<code>expr: (sum(harbor_up{cluster=\"$cluster\", %(job)s}) / count(harbor_up{cluster=\"$cluster\",   %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> javaActuator </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster) (jvm_memory_used_bytes{job=~\".+\", area=\"heap\"})*100/sum  by   (job, cluster) (jvm_memory_max_bytes{job=~\".+\", area=\"nonheap\"}) &gt; sum  by (job,   cluster) (jvm_memory_used_bytes{job=~\".+\", area=\"nonheap\"})*100/sum  by (job, cluster)   (jvm_memory_max_bytes{job=~\".+\", area=\"heap\"}) or (sum  by (job, cluster) (jvm_memory_used_bytes{job=~\".+\",   area=\"nonheap\"})*100)/sum by (job, cluster) (jvm_memory_max_bytes{job=~\".+\", area=\"heap\"})) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Java Actuator Heap High {{ $value }}%' name: ClusterAppJavaActuatorHeapHigh thresholds:   critical: 90   lowest: 0   operator: '&gt;='   warning: 75 </code> default<code>false</code> linkTo<code>- javaactuator </code> panel<code>expr: (sum by (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"})*100/sum  by   (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"}) &gt; sum  by   (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"})*100/sum  by   (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"}) or (sum  by   (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"})*100)/sum   by (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"})) OR on()   vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 90   lowest: 0   operator: '&gt;='   warning: 75 </code> <p></p> <p> jvm </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> lokiDistributed </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> mysqlExporter </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> nginxIngress </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: ((sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\", status!~\"[4-5].*\"}[5m]))   / sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\"}[5m]))   * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\"}[5m]))   + 100)) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Nginx Ingress Success Rate (non-4|5xx responses)   Low {{ printf \"%.0f\" $value }}%' name: ClusterAppNginxIngressSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxingress </code> panel<code>expr: ((sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\", %(job)s,   status!~\"[4-5].*\"}[5m])) / sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\",   %(job)s}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100)) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxIngressCertificateExpiry </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: bottomk(1, nginx_ingress_controller_ssl_expire_time_seconds{job=~\".+\"} - time())   / 60 / 60 / 24 linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Nginx Ingress Certificate Expiry in {{ printf   \"%.2f\" $value }} days' name: ClusterAppNginxIngressCertificateExpiry thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 8 </code> default<code>false</code> linkTo<code>- nginxingress </code> panel<code>dataLinks: - title: Detail   url:      /d/nginxingress?var-job=%(job)s&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to decimals: 0 expr: bottomk(1, nginx_ingress_controller_ssl_expire_time_seconds{cluster=\"$cluster\",   %(job)s} - time()) OR on() vector(-100000000000000005366162204393472) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -100000000000000005366162204393472 thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 691200 unit: s </code> <p></p> <p> nginxNrpe </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> nginxVts </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvts </code> panel<code>expr: (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\", %(job)s,   code!~\"[4-5].*\", code!=\"total\"}[5m])) / sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsEnhanced </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtsenhanced </code> panel<code>expr: (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\", %(job)s,   code!~\"[4-5].*\", code!=\"total\"}[5m])) / sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsEnhancedLegacy </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtsenhancedlegacy </code> panel<code>expr: (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\", %(job)s, code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsLegacy </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtslegacy </code> panel<code>expr: (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\", %(job)s, code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> openstack </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: min by (cluster, job) ({__name__=~\"openstack_.*_up\", job=~\".+\"}) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp OpenStack cluster health is CRITICAL, on cluster : {{ $externalLabels.cluster   }}' name: ClusterAppOpenStackHealthStatus thresholds:   critical: 0   operator: ==   warning: 10000 </code> default<code>false</code> linkTo<code>- openstack </code> panel<code>expr: min({__name__=~\"openstack_.*_up\", %(job)s, cluster=~\"$cluster\"}) OR vector(-1) gridPos:   w: 4 mappings: - text: OK   type: 1   value: 1 - text: OFFLINE   type: 1   value: -1 - text: CRITICAL   type: 1   value: 0 thresholds:   critical: 1   lowest: 0   operator: &lt; </code> <p></p> <p> phpFpm </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> postfix </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster) (postfix_size{job=~\".+\"})) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} mappings: - text: '-'   type: 1   value: -1 message: 'ClusterApp {{ $labels.job }}: Postfix Queue Size High {{ $value }}%' name: ClusterAppPostfixQueueSizeHigh thresholds:   critical: 10   lowest: 0   operator: '&gt;='   warning: 5 </code> default<code>false</code> linkTo<code>- postfix </code> panel<code>expr: (sum by (job) (postfix_size{cluster=\"$cluster\", %(job)s})) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 10   lowest: 0   operator: '&gt;='   warning: 5 unit: mailq </code> <p></p> <p> prometheus </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> pythonFlask </p> PropertyValuealert<code>customLables:   alertgroup: ClusterApp expr: (sum by (job, cluster)    (rate(flask_http_request_duration_seconds_count{job=~\".+\",status!~\"[4-5].*\"}[5m]))   / sum by (job, cluster) (rate(flask_http_request_duration_seconds_count{job=~\".+\"}[5m]))   * 100) &gt; 0 OR (sum by (job, cluster) (rate(flask_http_request_duration_seconds_count{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterApp {{ $labels.job }}: Python Flask Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterAppPythonFlaskSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- pythonflask </code> panel<code>expr: (sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s,status!~\"[4-5].*\"}[5m])) / sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> rabbitmq </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> sslExporter </p> PropertyValuealert<code>{} </code> default<code>false</code> linkTo<code>- ssl-exporter </code> panel<code>decimals: 0 expr: bottomk(1,ssl_cert_not_after{cluster=\"$cluster\"}-time() OR ssl_file_cert_not_after{cluster=\"$cluster\"}-time()   OR ssl_kubeconfig_cert_not_after{cluster=\"$cluster\"}-time() OR ssl_kubernetes_cert_not_after{cluster=\"$cluster\"}-time()) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -100000000000000005366162204393472 thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 691200 unit: s </code> <p></p> <p> websocket </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p>"},{"location":"docs/documentation/#vm","title":"vm","text":"PropertyValuemainmain <p> main </p> PropertyValuepanel<code>expr: sum(ALERTS{alertname!=\"Watchdog\", alertstate=\"firing\", severity=\"warning\", job=~\"%(job)s\",   alertgroup=~\"%(groupVM)s|%(groupVMApp)s\"} OR on() vector(0)) + sum(ALERTS{alertname!=\"Watchdog\",   alertstate=\"firing\", severity=\"critical\", job=~\"%(job)s\", alertgroup=~\"%(groupVM)s|%(groupVMApp)s\"}   OR on() vector(0)) * %(maxWarnings)d graphMode: none gridPos:   h: 3   w: 4 mappings: - from: 0   text: OK   to: 0   type: 2   value: '' - from: 1   text: Warning   to: 9999   type: 2   value: '' - from: 10000   text: Critical   to: 100000000000000005366162204393472   type: 2   value: '' thresholds:   critical: 10000   operator: '&gt;='   warning: 1 unit: none </code> <p></p>"},{"location":"docs/documentation/#vmapps","title":"vmApps","text":"PropertyValueapacheapache autoscalerautoscaler cAdvisorcAdvisor cephceph genericAppgenericApp harborharbor javaActuatorjavaActuator jvmjvm lokiDistributedlokiDistributed mysqlExportermysqlExporter nginxIngressnginxIngress nginxIngressCertificateExpirynginxIngressCertificateExpiry nginxNrpenginxNrpe nginxVtsnginxVts nginxVtsEnhancednginxVtsEnhanced nginxVtsEnhancedLegacynginxVtsEnhancedLegacy nginxVtsLegacynginxVtsLegacy openstackopenstack phpFpmphpFpm postfixpostfix prometheusprometheus pythonFlaskpythonFlask rabbitmqrabbitmq sslExportersslExporter websocketwebsocket <p> apache </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> autoscaler </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster) (autoscaler_healthy{job=~\".+\"}) / sum by (job, cluster)   (autoscaler_instances{job=~\".+\"}) * 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Autoscaler Health Low {{ $value }}%' name: ClusterVMAppAutoscalerHealthLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- autoscaler </code> panel<code>expr: (sum by (job) (autoscaler_healthy{cluster=\"$cluster\", %(job)s}) / sum by (job)   (autoscaler_instances{cluster=\"$cluster\", %(job)s}) * 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> cAdvisor </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> ceph </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: ceph_health_status{job=~\".+\"} linkGetParams: var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp Ceph cluster is UNHEALTHY, on cluster : {{ $externalLabels.cluster   }}' name: ClusterVMAppCephHealthStatus thresholds:   critical: 2   operator: '&gt;='   warning: 1 </code> default<code>false</code> linkTo<code>- ceph </code> panel<code>expr: ceph_health_status{cluster=\"$cluster\", %(job)s} gridPos:   w: 4 mappings: - text: HEALTHY   type: 1   value: 0 - text: WARNING   type: 1   value: 1 - text: ERROR   type: 1   value: 2 thresholds:   critical: 2   lowest: 0   operator: '&gt;='   warning: 1 </code> <p></p> <p> genericApp </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>description: GenericApp template. Used when application monitoring is requested but   appropriate template was not found. expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 gridPos:   w: 4 thresholds:   critical: 95   operator: &lt;   warning: 99 </code> <p></p> <p> harbor </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: harbor_up{job=~\".+\"} linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Harbor component \"{{ $labels.component }}\"   is down' name: ClusterVMAppHarborComponentDown thresholds:   critical: 0   operator: ==   warning: 0 </code> default<code>false</code> linkTo<code>- harbor </code> panel<code>expr: (sum(harbor_up{cluster=\"$cluster\", %(job)s}) / count(harbor_up{cluster=\"$cluster\",   %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> javaActuator </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster) (jvm_memory_used_bytes{job=~\".+\", area=\"heap\"})*100/sum  by   (job, cluster) (jvm_memory_max_bytes{job=~\".+\", area=\"nonheap\"}) &gt; sum  by (job,   cluster) (jvm_memory_used_bytes{job=~\".+\", area=\"nonheap\"})*100/sum  by (job, cluster)   (jvm_memory_max_bytes{job=~\".+\", area=\"heap\"}) or (sum  by (job, cluster) (jvm_memory_used_bytes{job=~\".+\",   area=\"nonheap\"})*100)/sum by (job, cluster) (jvm_memory_max_bytes{job=~\".+\", area=\"heap\"})) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Java Actuator Heap High {{ $value }}%' name: ClusterVMAppJavaActuatorHeapHigh thresholds:   critical: 90   lowest: 0   operator: '&gt;='   warning: 75 </code> default<code>false</code> linkTo<code>- javaactuator </code> panel<code>expr: (sum by (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"})*100/sum  by   (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"}) &gt; sum  by   (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"})*100/sum  by   (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"}) or (sum  by   (job) (jvm_memory_used_bytes{cluster=\"$cluster\", %(job)s, area=\"nonheap\"})*100)/sum   by (job) (jvm_memory_max_bytes{cluster=\"$cluster\", %(job)s, area=\"heap\"})) OR on()   vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 90   lowest: 0   operator: '&gt;='   warning: 75 </code> <p></p> <p> jvm </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> lokiDistributed </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> mysqlExporter </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> nginxIngress </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: ((sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\", status!~\"[4-5].*\"}[5m]))   / sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\"}[5m]))   * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_ingress_controller_requests{job=~\".+\"}[5m]))   + 100)) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Nginx Ingress Success Rate (non-4|5xx responses)   Low {{ printf \"%.0f\" $value }}%' name: ClusterVMAppNginxIngressSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxingress </code> panel<code>expr: ((sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\", %(job)s,   status!~\"[4-5].*\"}[5m])) / sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\",   %(job)s}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_ingress_controller_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100)) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxIngressCertificateExpiry </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: bottomk(1, nginx_ingress_controller_ssl_expire_time_seconds{job=~\".+\"} - time())   / 60 / 60 / 24 linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Nginx Ingress Certificate Expiry in {{ printf   \"%.2f\" $value }} days' name: ClusterVMAppNginxIngressCertificateExpiry thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 8 </code> default<code>false</code> linkTo<code>- nginxingress </code> panel<code>dataLinks: - title: Detail   url:      /d/nginxingress?var-job=%(job)s&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to decimals: 0 expr: bottomk(1, nginx_ingress_controller_ssl_expire_time_seconds{cluster=\"$cluster\",   %(job)s} - time()) OR on() vector(-100000000000000005366162204393472) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -100000000000000005366162204393472 thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 691200 unit: s </code> <p></p> <p> nginxNrpe </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> nginxVts </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterVMAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvts </code> panel<code>expr: (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\", %(job)s,   code!~\"[4-5].*\", code!=\"total\"}[5m])) / sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsEnhanced </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_vts_server_requests_total{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterVMAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtsenhanced </code> panel<code>expr: (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\", %(job)s,   code!~\"[4-5].*\", code!=\"total\"}[5m])) / sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_vts_server_requests_total{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsEnhancedLegacy </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterVMAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtsenhancedlegacy </code> panel<code>expr: (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\", %(job)s, code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> nginxVtsLegacy </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\", code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\",   code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job, cluster) (rate(nginx_server_requests{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Nginx VTS Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterVMAppNginxVTSSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- nginxvtslegacy </code> panel<code>expr: (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\", %(job)s, code!~\"[4-5].*\",   code!=\"total\"}[5m])) / sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s, code!=\"total\"}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(nginx_server_requests{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> openstack </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: min by (cluster, job) ({__name__=~\"openstack_.*_up\", job=~\".+\"}) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp OpenStack cluster health is CRITICAL, on cluster : {{ $externalLabels.cluster   }}' name: ClusterVMAppOpenStackHealthStatus thresholds:   critical: 0   operator: ==   warning: 10000 </code> default<code>false</code> linkTo<code>- openstack </code> panel<code>expr: min({__name__=~\"openstack_.*_up\", %(job)s, cluster=~\"$cluster\"}) OR vector(-1) gridPos:   w: 4 mappings: - text: OK   type: 1   value: 1 - text: OFFLINE   type: 1   value: -1 - text: CRITICAL   type: 1   value: 0 thresholds:   critical: 1   lowest: 0   operator: &lt; </code> <p></p> <p> phpFpm </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> postfix </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster) (postfix_size{job=~\".+\"})) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} mappings: - text: '-'   type: 1   value: -1 message: 'ClusterVMApp {{ $labels.job }}: Postfix Queue Size High {{ $value }}%' name: ClusterVMAppPostfixQueueSizeHigh thresholds:   critical: 10   lowest: 0   operator: '&gt;='   warning: 5 </code> default<code>false</code> linkTo<code>- postfix </code> panel<code>expr: (sum by (job) (postfix_size{cluster=\"$cluster\", %(job)s})) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 10   lowest: 0   operator: '&gt;='   warning: 5 unit: mailq </code> <p></p> <p> prometheus </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{%(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100 OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> pythonFlask </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVMApp expr: (sum by (job, cluster)    (rate(flask_http_request_duration_seconds_count{job=~\".+\",status!~\"[4-5].*\"}[5m]))   / sum by (job, cluster) (rate(flask_http_request_duration_seconds_count{job=~\".+\"}[5m]))   * 100) &gt; 0 OR (sum by (job, cluster) (rate(flask_http_request_duration_seconds_count{job=~\".+\"}[5m]))   + 100) linkGetParams: var-job={{ $labels.job }}&amp;var-cluster={{ $externalLabels.cluster }} message: 'ClusterVMApp {{ $labels.job }}: Python Flask Success Rate (non-4|5xx responses)   Low {{ $value }}%' name: ClusterVMAppPythonFlaskSuccessRateLow thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> default<code>false</code> linkTo<code>- pythonflask </code> panel<code>expr: (sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s,status!~\"[4-5].*\"}[5m])) / sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s}[5m])) * 100) &gt; 0 OR (sum by (job) (rate(flask_http_request_duration_seconds_count{cluster=\"$cluster\",   %(job)s}[5m])) + 100) OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 85   lowest: 0   operator: &lt;   warning: 95 </code> <p></p> <p> rabbitmq </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p> <p> sslExporter </p> PropertyValuealert<code>{} </code> default<code>false</code> linkTo<code>- ssl-exporter </code> panel<code>decimals: 0 expr: bottomk(1,ssl_cert_not_after{cluster=\"$cluster\"}-time() OR ssl_file_cert_not_after{cluster=\"$cluster\"}-time()   OR ssl_kubeconfig_cert_not_after{cluster=\"$cluster\"}-time() OR ssl_kubernetes_cert_not_after{cluster=\"$cluster\"}-time()) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -100000000000000005366162204393472 thresholds:   critical: 0   lowest: -100000000000000005366162204393472   operator: &lt;   warning: 691200 unit: s </code> <p></p> <p> websocket </p> PropertyValuealert<code>{} </code> default<code>false</code> panel<code>expr: (sum(up{cluster=\"$cluster\", %(job)s}) / count(up{cluster=\"$cluster\", %(job)s}))*100   OR on() vector(-1) gridPos:   w: 4 mappings: - text: '-'   type: 1   value: -1 thresholds:   critical: 95   lowest: 0   operator: &lt;   warning: 99 </code> <p></p>"},{"location":"docs/documentation/#l2","title":"L2","text":"PropertyValuecontainerOverviewcontainerOverview cpuPerNodecpuPerNode daemonSetOverviewdaemonSetOverview deploymentOverviewdeploymentOverview diskPerNodediskPerNode jobOverviewjobOverview memoryPerNodememoryPerNode networkPerNodenetworkPerNode nodeOverviewnodeOverview podOverviewpodOverview pvcOverviewpvcOverview statefulSetOverviewstatefulSetOverview vmvm"},{"location":"docs/documentation/#containeroverview","title":"containerOverview","text":"PropertyValuecontainerOverviewTablecontainerOverviewTable <p> containerOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(kube_pod_container_info{cluster=\"$cluster\", namespace=~\"$namespace\",   pod=~\"$pod\"}, container) </code> panel<code>expr: - \"sum by (container, namespace, pod) ((kube_pod_container_status_terminated * 0 or   kube_pod_container_status_terminated_reason{cluster=\\\"$cluster\\\", namespace=~\\\"\\   $namespace\\\", pod=~\\\"$pod\\\", container=~\\\"$container\\\", reason=\\\"Completed\\\"}) *   1) + \\nsum by (container, namespace, pod) (kube_pod_container_status_running{cluster=\\\"\\   $cluster\\\"} * 2) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   ContainerCreating\\\"}) * 3) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   CrashLoopBackOff\\\"}) * 4) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   CreateContainerConfigError\\\"}) * 5) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   ErrImagePull\\\"}) * 6) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   ImagePullBackOff\\\"}) * 7) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   CreateContainerError\\\"}) * 8) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   InvalidImageName\\\"}) * 9) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_waiting   * 0 or kube_pod_container_status_waiting_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   CrashLoopBackOff\\\"}) * 10) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_terminated   * 0 or kube_pod_container_status_terminated_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   OOMKilled\\\"}) * 11) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_terminated   * 0 or kube_pod_container_status_terminated_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   Error\\\"}) * 12) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_terminated   * 0 or kube_pod_container_status_terminated_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   ContainerCannotRun\\\"}) * 13) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_terminated   * 0 or kube_pod_container_status_terminated_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   DeadlineExceeded\\\"}) * 14) + \\nsum by (container, namespace, pod) ((kube_pod_container_status_terminated   * 0 or kube_pod_container_status_terminated_reason{cluster=\\\"$cluster\\\", reason=\\\"\\   Evicted\\\"}) * 15)\" - sum by (container, namespace, pod) (kube_pod_container_status_restarts_total{cluster=\"$cluster\",   namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"}) sort:   col: 5   desc: true styles: - pattern: Time   type: hidden - alias: Status   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: 'Value #A'   thresholds:   - 4   - 4   type: string   valueMaps:   - text: Terminated (Completed)     value: 1   - text: Running     value: 2   - text: Waiting (ContainerCreating)     value: 3   - text: Waiting (CrashLoopBackOff)     value: 4   - text: Waiting (CreateContainerConfigError)     value: 5   - text: Waiting (ErrImagePull)     value: 6   - text: Waiting (ImagePullBackOff)     value: 7   - text: Waiting (CreateContainerError)     value: 8   - text: Waiting (InvalidImageName)     value: 9   - text: Waiting (CrashLoopBackOff)     value: 10   - text: Terminated (OOMKilled)     value: 11   - text: Terminated (Error)     value: 12   - text: Terminated (ContainerCannotRun)     value: 13   - text: Terminated (DeadlineExceeded)     value: 14   - text: Terminated (Evicted)     value: 15 - alias: Restarts   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   pattern: 'Value #B'   thresholds:   - 5   - 10   type: number - alias: Container   link: true   linkTooltip: Detail   linkUrl:      /d/containerdetail?var-container=${__cell_3}&amp;var-namespace=${__cell_1}&amp;var-pod=${__cell_2}&amp;var-view=container&amp;var-search=&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: container - alias: Namespace   pattern: namespace   type: string - alias: Pod   pattern: pod   type: string title: Containers transformations: - id: merge   options: {} - id: organize   options:     excludeByName:       Time: false     indexByName:       Time: 0       'Value #A': 4       'Value #B': 5       container: 3       namespace: 1       pod: 2     renameByName: {} </code> <p></p>"},{"location":"docs/documentation/#cpupernode","title":"cpuPerNode","text":"PropertyValuecpuPerNodePolystatcpuPerNodePolystat <p> cpuPerNodePolystat </p> PropertyValuebase<code>\"basePolystatTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(node_uname_info{cluster=\"$cluster\", job=~\"$job\"},   nodename) </code> panel<code>default_click_through:    /d/nodeexporter?var-job=$job&amp;var-instance=${__cell_name}&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: \"avg(round((1 - (avg by (instance, pod) (irate(node_cpu_seconds_total{cluster=\\\"\\   $cluster\\\", job=~\\\"$job\\\", mode=\\\"idle\\\"}[5m])))) * 100)\\n* on(instance, pod) group_left(nodename)   \\n   node_uname_info{cluster=\\\"$cluster\\\", nodename=~\\\"$instance\\\"}) by (nodename)\" fontColor: '#ffffff' global_thresholds: - color: '#56a64b'   state: 0   value: 0 - color: '#ff780a'   state: 1   value: 75 - color: '#e02f44'   state: 2   value: 90 global_unit_format: percent title: CPU per Node </code> <p></p>"},{"location":"docs/documentation/#daemonsetoverview","title":"daemonSetOverview","text":"PropertyValuedaemonSetOverviewTabledaemonSetOverviewTable <p> daemonSetOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(kube_daemonset_status_desired_number_scheduled{cluster=\"$cluster\",   namespace=~\"$namespace\"}, daemonset) </code> panel<code>expr: - sum by (daemonset, namespace) (kube_daemonset_status_number_misscheduled{cluster=\"$cluster\",   namespace=~\"$namespace\", daemonset=~\"$daemonset\"}) - sum by (daemonset, namespace) (kube_daemonset_status_desired_number_scheduled{cluster=\"$cluster\",   namespace=~\"$namespace\", daemonset=~\"$daemonset\"}) - sum by (daemonset, namespace)   (kube_daemonset_updated_number_scheduled{cluster=\"$cluster\", namespace=~\"$namespace\",   daemonset=~\"$daemonset\"}) - sum by (daemonset, namespace) (kube_daemonset_status_desired_number_scheduled{cluster=\"$cluster\",   namespace=~\"$namespace\", daemonset=~\"$daemonset\"}) - sum by (daemonset, namespace)   (kube_daemonset_status_number_available{cluster=\"$cluster\", namespace=~\"$namespace\",   daemonset=~\"$daemonset\"}) - sum by (daemonset, namespace) (kube_daemonset_status_desired_number_scheduled{cluster=\"$cluster\",   namespace=~\"$namespace\", daemonset=~\"$daemonset\"}) - sum by (daemonset, namespace)   (kube_daemonset_status_number_ready{cluster=\"$cluster\", namespace=~\"$namespace\",   daemonset=~\"$daemonset\"}) sort:   col: 5   desc: true styles: - pattern: Time   type: hidden - alias: Scheduled   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 2   pattern: 'Value #A'   rangeMaps:   - from: 0     text: OK     to: 0   - from: 1     text: Failed     to: 100000000000000005366162204393472   thresholds:   - 1   - 1   type: string - alias: Updated   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 2   pattern: 'Value #B'   rangeMaps:   - from: 0     text: OK     to: 0   - from: 1     text: Failed     to: 100000000000000005366162204393472   thresholds:   - 1   - 1   type: string - alias: Available   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 2   pattern: 'Value #C'   rangeMaps:   - from: 0     text: OK     to: 0   - from: 1     text: Failed     to: 100000000000000005366162204393472   thresholds:   - 1   - 1   type: string - alias: Ready   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 2   pattern: 'Value #D'   rangeMaps:   - from: 0     text: OK     to: 0   - from: 1     text: Failed     to: 100000000000000005366162204393472   thresholds:   - 1   - 1   type: string - alias: DaemonSet   pattern: daemonset   type: string - alias: Namespace   link: true   linkTooltip: Detail   linkUrl:      /d/containerdetail?var-namespace=$__cell&amp;var-pod=All&amp;var-view=pod&amp;var-search=&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: namespace title: DaemonSets transformations: - id: merge   options: {} - id: organize   options:     excludeByName:       Time: true     indexByName:       Time: 0       'Value #A': 3       'Value #B': 4       'Value #C': 5       'Value #D': 6       daemonset: 2       namespace: 1     renameByName: {} </code> <p></p>"},{"location":"docs/documentation/#deploymentoverview","title":"deploymentOverview","text":"PropertyValuedeploymentOverviewTabledeploymentOverviewTable <p> deploymentOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(kube_deployment_status_replicas{cluster=\"$cluster\",   namespace=~\"$namespace\"}, deployment) </code> panel<code>expr: - sum by (deployment, namespace) (kube_deployment_status_replicas{cluster=\"$cluster\",   namespace=~\"$namespace\", deployment=~\"$deployment\"}) - sum by (deployment, namespace)   (kube_deployment_status_replicas_updated{cluster=\"$cluster\", namespace=~\"$namespace\",   deployment=~\"$deployment\"}) - sum by (deployment, namespace) (kube_deployment_status_replicas{cluster=\"$cluster\",   namespace=~\"$namespace\", deployment=~\"$deployment\"}) - sum by (deployment, namespace)   (kube_deployment_status_replicas_available{cluster=\"$cluster\", namespace=~\"$namespace\",   deployment=~\"$deployment\"}) sort:   col: 3   desc: true styles: - pattern: Time   type: hidden - alias: Updated   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 2   pattern: 'Value #A'   rangeMaps:   - from: 0     text: OK     to: 0   - from: 1     text: Failed     to: 100000000000000005366162204393472   thresholds:   - 1   - 1   type: string - alias: Available   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 2   pattern: 'Value #B'   rangeMaps:   - from: 0     text: OK     to: 0   - from: 1     text: Failed     to: 100000000000000005366162204393472   thresholds:   - 1   - 1   type: string - alias: Deployment   pattern: deployment   type: string - alias: Namespace   link: true   linkTooltip: Detail   linkUrl:      /d/containerdetail?var-namespace=$__cell&amp;var-pod=All&amp;var-view=pod&amp;var-search=&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: namespace title: Deployments transformations: - id: merge   options: {} - id: organize   options:     excludeByName:       Time: true     indexByName:       Time: 0       'Value #A': 3       'Value #B': 4       deployment: 2       namespace: 1     renameByName: {} </code> <p></p>"},{"location":"docs/documentation/#diskpernode","title":"diskPerNode","text":"PropertyValuediskPerNodePolystatdiskPerNodePolystat <p> diskPerNodePolystat </p> PropertyValuebase<code>\"basePolystatTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(node_uname_info{cluster=\"$cluster\", job=~\"$job\"},   nodename) </code> panel<code>default_click_through:    /d/nodeexporter?var-job=$job&amp;var-instance=${__cell_name}&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: \"max(round(\\n(sum(node_filesystem_size_bytes{cluster=\\\"$cluster\\\", job=~\\\"$job\\\"\\   }) by (instance, device, pod) - sum(node_filesystem_free_bytes{cluster=\\\"$cluster\\\"\\   , job=~\\\"$job\\\"}) by (instance, device, pod)) /\\n(sum(node_filesystem_size_bytes{cluster=\\\"\\   $cluster\\\", job=~\\\"$job\\\"}) by (instance, device, pod) - sum(node_filesystem_free_bytes{cluster=\\\"\\   $cluster\\\", job=~\\\"$job\\\"}) by (instance, device, pod) +\\nsum(node_filesystem_avail_bytes{cluster=\\\"\\   $cluster\\\", job=~\\\"$job\\\"}) by (instance, device, pod))\\n * 100\\n) * on(instance,   pod) group_left(nodename) \\n   node_uname_info{cluster=\\\"$cluster\\\", nodename=~\\\"\\   $instance\\\"}) by (nodename)\" fontColor: '#ffffff' global_thresholds: - color: '#56a64b'   state: 0   value: 0 - color: '#ff780a'   state: 1   value: 75 - color: '#e02f44'   state: 2   value: 90 global_unit_format: percent title: Disk per Node  <p></p>"},{"location":"docs/documentation/#joboverview","title":"jobOverview","text":"PropertyValuejobOverviewTablejobOverviewTable <p> jobOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(kube_job_info{cluster=\"$cluster\", namespace=~\"$namespace\"},   job_name) </code> panel<code>expr: - \"sum by (job_name, namespace) (clamp_max(kube_job_status_succeeded{cluster=\\\"$cluster\\\"\\   , namespace=~\\\"$namespace\\\", job_name=~\\\"$job_name\\\"}, 1) * 1) * on(job_name, namespace)   group_left(owner_name) kube_job_owner{cluster=\\\"$cluster\\\", namespace=~\\\"$namespace\\\"\\   , job_name=~\\\"$job_name\\\"} +\\nsum by (job_name, namespace) (clamp_max(kube_job_status_active{cluster=\\\"\\   $cluster\\\", namespace=~\\\"$namespace\\\", job_name=~\\\"$job_name\\\"}, 1) * 2) * on(job_name,   namespace) group_left(owner_name) kube_job_owner{cluster=\\\"$cluster\\\", namespace=~\\\"\\   $namespace\\\", job_name=~\\\"$job_name\\\"} +\\nsum by (job_name, namespace) (clamp_max(kube_job_status_failed{cluster=\\\"\\   $cluster\\\", namespace=~\\\"$namespace\\\", job_name=~\\\"$job_name\\\"}, 1) * 3) * on(job_name,   namespace) group_left(owner_name) kube_job_owner{cluster=\\\"$cluster\\\", namespace=~\\\"\\   $namespace\\\", job_name=~\\\"$job_name\\\"}\\n\" sort:   col: 3   desc: true styles: - pattern: Time   type: hidden - alias: Status   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: Value   thresholds:   - 3   - 3   type: string   valueMaps:   - text: Succeeded     value: 1   - text: Active     value: 2   - text: Failed     value: 3 - alias: Job name   pattern: job_name   type: string - alias: Owner   pattern: owner_name   type: string - alias: Namespace   link: true   linkTooltip: Detail   linkUrl:      /d/containerdetail?var-namespace=$__cell&amp;var-container=All&amp;var-view=container&amp;var-search=&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: namespace title: Jobs transformations: - id: organize   options:     excludeByName:       Time: true     indexByName:       Time: 0       Value: 4       job_name: 2       namespace: 1       owner_name: 3     renameByName: {} </code> <p></p>"},{"location":"docs/documentation/#memorypernode","title":"memoryPerNode","text":"PropertyValuememoryPerNodePolystatmemoryPerNodePolystat <p> memoryPerNodePolystat </p> PropertyValuebase<code>\"basePolystatTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(node_uname_info{cluster=\"$cluster\", job=~\"$job\"},   nodename) </code> panel<code>default_click_through:    /d/nodeexporter?var-job=$job&amp;var-instance=${__cell_name}&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: \"avg(round((1 - (sum(node_memory_MemAvailable_bytes{cluster=\\\"$cluster\\\", job=~\\\"\\   $job\\\"}) by (instance, pod) / sum(node_memory_MemTotal_bytes{cluster=\\\"$cluster\\\"\\   , job=~\\\"$job\\\"}) by (instance, pod) )) * 100)\\n* on(instance, pod) group_left(nodename)   \\n   node_uname_info{cluster=\\\"$cluster\\\", nodename=~\\\"$instance\\\"}) by (nodename)\" fontColor: '#ffffff' global_thresholds: - color: '#56a64b'   state: 0   value: 0 - color: '#ff780a'   state: 1   value: 75 - color: '#e02f44'   state: 2   value: 90 global_unit_format: percent title: Memory per Node  <p></p>"},{"location":"docs/documentation/#networkpernode","title":"networkPerNode","text":"PropertyValuenetworkPerNodePolystatnetworkPerNodePolystat <p> networkPerNodePolystat </p> PropertyValuebase<code>\"basePolystatTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(node_uname_info{cluster=\"$cluster\", job=~\"$job\"},   nodename) </code> panel<code>default_click_through:    /d/nodeexporter?var-job=$job&amp;var-instance=${__cell_name}&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: \"avg((sum(rate(node_network_transmit_errs_total{cluster=\\\"$cluster\\\", job=~\\\"\\   $job\\\", device!~\\\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\\\"}[5m])) \\   \\ by (instance, pod) \\n   + sum(rate(node_network_receive_errs_total{cluster=\\\"\\   $cluster\\\", job=~\\\"$job\\\", device!~\\\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\\\"\\   }[5m])) by (instance, pod))\\n* on(instance, pod) group_left(nodename) \\n   node_uname_info{cluster=\\\"\\   $cluster\\\", nodename=~\\\"$instance\\\"}) by (nodename)\" fontColor: '#ffffff' global_thresholds: - color: '#56a64b'   state: 0   value: 0 - color: '#ff780a'   state: 1   value: 10 - color: '#e02f44'   state: 2   value: 30 global_unit_format: pps title: Network Errors per Node </code> <p></p>"},{"location":"docs/documentation/#nodeoverview","title":"nodeOverview","text":"PropertyValuenodeOverviewTablenodeOverviewTable <p> nodeOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>{} </code> panel<code>expr: - sum by (node) (kube_node_spec_unschedulable{cluster=\"$cluster\"}) - sum by (node) (kube_node_status_condition{cluster=\"$cluster\", condition=\"DiskPressure\",   status=~\"true|unknown\"}) - sum by (node) (kube_node_status_condition{cluster=\"$cluster\", condition=\"MemoryPressure\",   status=~\"true|unknown\"}) - sum by (node) (kube_node_status_condition{cluster=\"$cluster\", condition=\"PIDPressure\",   status=~\"true|unknown\"}) - sum by (node) (kube_node_status_condition{cluster=\"$cluster\", condition=\"Ready\",   status=~\"false|unknown\"}) sort:   col: 6   desc: true styles: - pattern: Time   type: hidden - alias: Schedulable   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: 'Value #A'   thresholds:   - 1   - 1   type: string   valueMaps:   - text: Failed     value: 1   - text: OK     value: 0 - alias: Disk Pressure   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: 'Value #B'   thresholds:   - 1   - 1   type: string   valueMaps:   - text: Failed     value: 1   - text: OK     value: 0 - alias: Memory Pressure   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: 'Value #C'   thresholds:   - 1   - 1   type: string   valueMaps:   - text: Failed     value: 1   - text: OK     value: 0 - alias: PID Pressure   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: 'Value #D'   thresholds:   - 1   - 1   type: string   valueMaps:   - text: Failed     value: 1   - text: OK     value: 0 - alias: Ready   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: 'Value #E'   thresholds:   - 1   - 1   type: string   valueMaps:   - text: Failed     value: 1   - text: OK     value: 0 - alias: Node   link: true   linkTooltip: Detail   linkUrl:      /d/containerdetail?var-view=pod&amp;var-instance=$__cell&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: node title: Nodes </code> <p></p>"},{"location":"docs/documentation/#podoverview","title":"podOverview","text":"PropertyValuepodOverviewTablepodOverviewTable <p> podOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(kube_pod_info{cluster=\"$cluster\", namespace=~\"$namespace\"},   pod) </code> panel<code>expr: - \"sum by (namespace, pod) (kube_pod_status_phase{cluster=\\\"$cluster\\\", namespace=~\\\"\\   $namespace\\\", phase=\\\"Running\\\"} * 1) +\\nsum by (namespace, pod) (kube_pod_status_phase{cluster=\\\"\\   $cluster\\\", namespace=~\\\"$namespace\\\", phase=\\\"Succeeded\\\"} * 2) +\\nsum by (namespace,   pod) (kube_pod_status_phase{cluster=\\\"$cluster\\\", namespace=~\\\"$namespace\\\", phase=\\\"\\   Unknown\\\"} * 3) +\\nsum by (namespace, pod) (kube_pod_status_phase{cluster=\\\"$cluster\\\"\\   , namespace=~\\\"$namespace\\\", phase=\\\"Failed\\\"} * 4) +\\nsum by (namespace, pod) (kube_pod_status_phase{cluster=\\\"\\   $cluster\\\", namespace=~\\\"$namespace\\\", pod=~\\\"$pod\\\", phase=\\\"Pending\\\"} * 5)\\n\" sort:   col: 3   desc: true styles: - pattern: Time   type: hidden - alias: Status   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: Value   thresholds:   - 3   - 3   type: string   valueMaps:   - text: Running     value: 1   - text: Succeeded     value: 2   - text: Unknown     value: 3   - text: Failed     value: 4   - text: Pending     value: 5 - alias: Namespace   pattern: namespace   type: string - alias: Pod   link: true   linkTooltip: Detail   linkUrl:      /d/containerdetail?var-container=All&amp;var-view=pod&amp;var-namespace=${__cell_1}&amp;var-pod=${__cell_2}&amp;var-search=&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: pod title: Pods </code> <p></p>"},{"location":"docs/documentation/#pvcoverview","title":"pvcOverview","text":"PropertyValuepvcOverviewTablepvcOverviewTable <p> pvcOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(kube_persistentvolumeclaim_info{cluster=\"$cluster\",   namespace=~\"$namespace\"}, persistentvolumeclaim) </code> panel<code>description: Capacity is available only for remote pvc. expr: - sum by (persistentvolumeclaim, namespace) (((kubelet_volume_stats_capacity_bytes{cluster=\"$cluster\",   namespace=~\"$namespace\", persistentvolumeclaim=~\"$pvc\"} - kubelet_volume_stats_available_bytes{cluster=\"$cluster\",   namespace=~\"$namespace\", persistentvolumeclaim=~\"$pvc\"}) / kubelet_volume_stats_capacity_bytes{cluster=\"$cluster\",   namespace=~\"$namespace\", persistentvolumeclaim=~\"$pvc\"}) * 100) - \"sum by (persistentvolumeclaim, namespace) (kube_persistentvolumeclaim_status_phase{cluster=\\\"\\   $cluster\\\", namespace=~\\\"$namespace\\\", persistentvolumeclaim=~\\\"$pvc\\\", phase=\\\"\\   Bound\\\"} * 1) +\\nsum by (persistentvolumeclaim, namespace) (kube_persistentvolumeclaim_status_phase{cluster=\\\"\\   $cluster\\\", namespace=~\\\"$namespace\\\", persistentvolumeclaim=~\\\"$pvc\\\", phase=\\\"\\   Lost\\\"} * 2) +\\nsum by (persistentvolumeclaim, namespace) (kube_persistentvolumeclaim_status_phase{cluster=\\\"\\   $cluster\\\", namespace=~\\\"$namespace\\\", persistentvolumeclaim=~\\\"$pvc\\\", phase=\\\"\\   Pending\\\"} * 3)\\n\" sort:   col: 3   desc: true styles: - pattern: Time   type: hidden - alias: Capacity   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   pattern: 'Value #A'   thresholds:   - 85   - 97   type: number   unit: percent - alias: Status   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 1   pattern: 'Value #B'   thresholds:   - 2   - 2   type: string   valueMaps:   - text: Bound     value: 1   - text: Lost     value: 2   - text: Pending     value: 3 - alias: PVC   link: true   linkTooltip: Detail   linkUrl:      /d/persistentvolumes?var-namespace=${__cell_1}&amp;var-pvc=${__cell_2}&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: persistentvolumeclaim - alias: Namespace   pattern: namespace   type: string title: Persistent Volumes </code> <p></p>"},{"location":"docs/documentation/#statefulsetoverview","title":"statefulSetOverview","text":"PropertyValuestatefulSetOverviewTablestatefulSetOverviewTable <p> statefulSetOverviewTable </p> PropertyValuebase<code>\"baseTableTemplate\"</code> dashboardInfo<code>grafanaTemplateQuery: label_values(kube_statefulset_status_replicas{cluster=\"$cluster\",   namespace=~\"$namespace\"}, statefulset) </code> panel<code>expr: - sum by (statefulset, namespace) (kube_statefulset_status_replicas_updated{cluster=\"$cluster\",   namespace=~\"$namespace\", statefulset=~\"$statefulset\"}) - sum by (statefulset, namespace) (kube_statefulset_status_replicas{cluster=\"$cluster\",   namespace=~\"$namespace\", statefulset=~\"$statefulset\"}) - sum by (statefulset, namespace)   (kube_statefulset_status_replicas_ready{cluster=\"$cluster\", namespace=~\"$namespace\",   statefulset=~\"$statefulset\"}) sort:   col: 4   desc: true styles: - pattern: Time   type: hidden - alias: Updated   pattern: 'Value #A'   type: number - alias: Ready   colorMode: cell   colors:   - '#56a64b'   - '#ff780a'   - '#e02f44'   mappingType: 2   pattern: 'Value #B'   rangeMaps:   - from: 0     text: OK     to: 0   - from: 1     text: Failed     to: 100000000000000005366162204393472   thresholds:   - 1   - 1   type: string - alias: StatefulSet   link: true   linkTooltip: Detail   linkUrl:      /d/statefulset?var-namespace=${__cell_1}&amp;var-statefulset=${__cell_2}&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: statefulset - alias: Namespace   link: true   linkTooltip: Detail   linkUrl:      /d/containerdetail?var-namespace=$__cell&amp;var-pod=All&amp;var-view=pod&amp;var-search=&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to   pattern: namespace title: StatefulSets </code> <p></p>"},{"location":"docs/documentation/#vm_1","title":"vm","text":"PropertyValuemostUtilizedVMCPUmostUtilizedVMCPU mostUtilizedVMDiskmostUtilizedVMDisk mostUtilizedVMNetworkErrorsmostUtilizedVMNetworkErrors mostUtilizedVMRAMmostUtilizedVMRAM overallNetworkErrorsoverallNetworkErrors overallUtilizationCPUoverallUtilizationCPU overallUtilizationDiskoverallUtilizationDisk overallUtilizationRAMoverallUtilizationRAM targetDowntargetDown totalCorestotalCores totalDisktotalDisk totalRAMtotalRAM usedCoresusedCores usedDiskusedDisk usedRAMusedRAM <p> mostUtilizedVMCPU </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: round((1 - (avg(irate(node_cpu_seconds_total{job=~\"%s\", mode=\"idle\"}[5m]) *   on(instance) group_left(nodename) (node_uname_info)) by (job, nodename) )) * 100) linkGetParams: var-instance={{ $labels.nodename }} message: 'VM {{ $labels.nodename }}: High CPU Utilization {{ $value }}%' name: VMCPUUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: max(round((1 - (avg(irate(node_cpu_seconds_total{job=~\"$job\", mode=\"idle\"}[5m])   * on(instance) group_left(nodename) (node_uname_info)) by (job, nodename) )) * 100)) gridPos:   w: 3   x: 3   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized VM </code> <p></p> <p> mostUtilizedVMDisk </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: round((sum(node_filesystem_size_bytes{job=~\"%s\"} * on(instance) group_left(nodename)   (node_uname_info)) by (job, nodename, device) - sum(node_filesystem_free_bytes{job=~\"%s\"}   * on(instance) group_left(nodename) (node_uname_info)) by (job, nodename, device))   / ((sum(node_filesystem_size_bytes{job=~\"%s\"} * on(instance) group_left(nodename)   (node_uname_info)) by (job, nodename, device) - sum(node_filesystem_free_bytes{job=~\"%s\"}   * on(instance) group_left(nodename) (node_uname_info)) by (job, nodename, device))   + sum(node_filesystem_avail_bytes{job=~\"%s\"} * on(instance) group_left(nodename)   (node_uname_info)) by (job, nodename, device)) * 100 &gt; 0) linkGetParams: var-instance={{ $labels.nodename }} message: 'VM {{ $labels.nodename }}: High Disk Utilization {{ $value }}%' name: VMDiskUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: max(round((sum(node_filesystem_size_bytes{job=~\"$job\"} * on(instance) group_left(nodename)   (node_uname_info)) by (job, nodename, device) - sum(node_filesystem_free_bytes{job=~\"$job\"}   * on(instance) group_left(nodename) (node_uname_info)) by (job, nodename, device))   / ((sum(node_filesystem_size_bytes{job=~\"$job\"} * on(instance) group_left(nodename)   (node_uname_info)) by (job, nodename, device) - sum(node_filesystem_free_bytes{job=~\"$job\"}   * on(instance) group_left(nodename) (node_uname_info)) by (job, nodename, device))   + sum(node_filesystem_avail_bytes{job=~\"$job\"} * on(instance) group_left(nodename)   (node_uname_info)) by (job, nodename, device)) * 100 &gt; 0)) gridPos:   w: 3   x: 15   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized VM  <p></p> <p> mostUtilizedVMNetworkErrors </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: sum(rate(node_network_transmit_errs_total{job=~\"%s\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance) group_left(nodename) (node_uname_info) ) by (job, nodename)   + sum(rate(node_network_receive_errs_total{job=~\"%s\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance) group_left(nodename) (node_uname_info) ) by (job, nodename) linkGetParams: var-instance={{ $labels.nodename }} message: 'VM {{ $labels.nodename }}: High Network Errors Count {{ $value }}%' name: VMNetworkErrorsHigh thresholds:   critical: 15   operator: '&gt;='   warning: 10 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: max(sum(rate(node_network_transmit_errs_total{job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance) group_left(nodename) (node_uname_info) ) by (job, nodename)   + sum(rate(node_network_receive_errs_total{job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance) group_left(nodename) (node_uname_info) ) by (job, nodename)) gridPos:   w: 3   x: 21   y: 6 thresholds:   critical: 15   operator: '&gt;='   warning: 10 title: Most Affected VM unit: pps </code> <p></p> <p> mostUtilizedVMRAM </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: round((1 - sum by (job, nodename) (node_memory_MemAvailable_bytes{job=~\"%s\"}   * on(instance) group_left(nodename) (node_uname_info)) / sum by (job, nodename)   (node_memory_MemTotal_bytes{job=~\"%s\"} * on(instance) group_left(nodename) (node_uname_info)))   * 100) linkGetParams: var-instance={{ $labels.nodename }} message: 'VM {{ $labels.nodename }}: High RAM Utilization {{ $value }}%' name: VMRAMUtilizationHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: max(round((1 - sum by (job, nodename) (node_memory_MemAvailable_bytes{job=~\"$job\"}   * on(instance) group_left(nodename) (node_uname_info)) / sum by (job, nodename)   (node_memory_MemTotal_bytes{job=~\"$job\"} * on(instance) group_left(nodename) (node_uname_info)))   * 100)) gridPos:   w: 3   x: 9   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Most Utilized VM  <p></p> <p> overallNetworkErrors </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: sum(sum(rate(node_network_transmit_errs_total{job=~\"%s\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, cluster) group_left(nodename) (node_uname_info) ) by (job,   nodename) + sum(rate(node_network_receive_errs_total{job=~\"%s\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, cluster) group_left(nodename) (node_uname_info) ) by (job, nodename)) message: VM High Overall Network Errors Count {{ $value }}% name: VMNetworkOverallErrorsHigh thresholds:   critical: 15   operator: '&gt;='   warning: 10 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: sum(sum(rate(node_network_transmit_errs_total{job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}   [5m]) * on(instance, cluster) group_left(nodename) (node_uname_info) ) by (job,   nodename) + sum(rate(node_network_receive_errs_total{job=~\"$job\", device!~\"lo|veth.+|docker.+|flannel.+|cali.+|cbr.|cni.+|br.+\"}[5m])   * on(instance, cluster) group_left(nodename) (node_uname_info) ) by (job, nodename)) gridPos:   w: 3   x: 18   y: 6 thresholds:   critical: 15   operator: '&gt;='   warning: 10 title: Overall Errors unit: pps </code> <p></p> <p> overallUtilizationCPU </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: avg(round((1 - (avg(irate(node_cpu_seconds_total{job=~\"%s\", mode=\"idle\"}[5m])   * on(instance, cluster) group_left(nodename) (node_uname_info)) by (job, nodename)   )) * 100)) message: VM High CPU Overall Utilization {{ $value }}% name: VMCPUOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to expr: avg(round((1 - (avg(irate(node_cpu_seconds_total{job=~\"$job\", mode=\"idle\"}[5m])   * on(instance, cluster) group_left(nodename) (node_uname_info)) by (job, nodename)   )) * 100)) gridPos:   w: 3   x: 0   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization </code> <p></p> <p> overallUtilizationDisk </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: round((sum(node_filesystem_size_bytes{job=~\"%s\"}) - sum(node_filesystem_free_bytes{job=~\"%s\"}))   / (sum(node_filesystem_size_bytes{job=~\"%s\"}) - sum(node_filesystem_free_bytes{job=~\"%s\"})   + sum(node_filesystem_avail_bytes{job=~\"%s\"})) * 100 &gt; 0) message: VM High Disk Overall Utilization {{ $value }}% name: VMDiskOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the disk utilization is calculated using the fraction:\\n   ```\\n/( + )\\n```\\nThe value of    is reduced by  5% of the available disk capacity, because   \\nthe file system marks   5% of the available disk capacity as reserved. \\nIf less than 5% is free, using   the remaining reserved space requires root privileges.\\nAny non-privileged users   and processes are unable to write new data to the partition. See the list of explicitly   ignored mount points and file systems [here](https://github.com/dNationCloud/kubernetes-monitoring-stack/blob/main/chart/values.yaml)\" expr: round((sum(node_filesystem_size_bytes{job=~\"$job\"}) - sum(node_filesystem_free_bytes{job=~\"$job\"}))   / (sum(node_filesystem_size_bytes{job=~\"$job\"}) - sum(node_filesystem_free_bytes{job=~\"$job\"})   + sum(node_filesystem_avail_bytes{job=~\"$job\"})) * 100 &gt; 0) gridPos:   w: 3   x: 12   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> overallUtilizationRAM </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: avg(round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"%s\"}   * on(instance, cluster) group_left(nodename) (node_uname_info)) / sum by (job, nodename,   cluster) (node_memory_MemTotal_bytes{job=~\"%s\"} * on(instance, cluster) group_left(nodename)   (node_uname_info))) * 100)) message: VM High RAM Overall Utilization {{ $value }}% name: VMRAMOverallHigh thresholds:   critical: 90   operator: '&gt;='   warning: 75 </code> linkTo<code>- nodeexporter </code> panel<code>dataLinks: - title: System Overview   url:      /d/nodeexporter?var-job=$job&amp;var-datasource=$datasource&amp;var-cluster=$cluster&amp;from=$__from&amp;to=$__to description: \"The percentage of the memory utilization is calculated by:\\n```\\n1 -   (/)\\n```\" expr: avg(round((1 - sum by (job, nodename, cluster) (node_memory_MemAvailable_bytes{job=~\"$job\"}   * on(instance, cluster) group_left(nodename) (node_uname_info)) / sum by (job, nodename,   cluster) (node_memory_MemTotal_bytes{job=~\"$job\"} * on(instance, cluster) group_left(nodename)   (node_uname_info))) * 100)) gridPos:   w: 3   x: 6   y: 6 thresholds:   critical: 90   operator: '&gt;='   warning: 75 title: Overall Utilization  <p></p> <p> targetDown </p> PropertyValuealert<code>customLables:   alertgroup: ClusterVM expr: 100 * (count by(job, namespace, service) (up{job=~\"%s\"} == 0) / count by(job,   namespace, service) (up{job=~\"%s\"})) message: '{{ printf \"%.4g\" $value }}% of the {{ $labels.job }}/{{ $labels.service   }} targets in {{ $labels.namespace }} namespace are down.' name: VMTargetDown thresholds:   critical: 90   operator: '&gt;='   warning: 10 </code> panel<code>null</code> <p></p> <p> totalCores </p> PropertyValuepanel<code>colorMode: value expr: count(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\", mode=\"system\"}) graphMode: none gridPos:   h: 2   w: 3   x: 3   y: 9 thresholds:   color: '#858187'   value: title: Total Cores unit: none </code> <p></p> <p> totalDisk </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\"}) graphMode: none gridPos:   h: 2   w: 3   x: 15   y: 9 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> totalRAM </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\"}) graphMode: none gridPos:   h: 2   w: 3   x: 9   y: 9 thresholds:   color: '#858187'   value: title: Total unit: bytes </code> <p></p> <p> usedCores </p> PropertyValuepanel<code>colorMode: value expr: (1 - (avg(irate(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\", mode=\"idle\"}[5m]))))   * count(node_cpu_seconds_total{cluster=\"$cluster\", job=~\"$job\", mode=\"system\"}) graphMode: none gridPos:   h: 2   w: 3   x: 0   y: 9 thresholds:   color: '#858187'   value: title: Used Cores unit: none </code> <p></p> <p> usedDisk </p> PropertyValuepanel<code>colorMode: value expr: sum(node_filesystem_size_bytes{cluster=\"$cluster\", job=~\"$job\"}) - sum(node_filesystem_free_bytes{cluster=\"$cluster\",   job=~\"$job\"}) graphMode: none gridPos:   h: 2   w: 3   x: 12   y: 9 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p> <p> usedRAM </p> PropertyValuepanel<code>colorMode: value expr: sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\"}) * (((1 - sum(node_memory_MemAvailable_bytes{cluster=\"$cluster\",   job=~\"$job\"}) / sum(node_memory_MemTotal_bytes{cluster=\"$cluster\", job=~\"$job\"})))) graphMode: none gridPos:   h: 2   w: 3   x: 6   y: 9 thresholds:   color: '#858187'   value: title: Used unit: bytes </code> <p></p>"},{"location":"docs/documentation/#commonthresholds","title":"commonThresholds","text":"PropertyValueappapp controlPlanecontrolPlane criticalPanelcriticalPanel k8sk8s nodenode warningPanelwarningPanel"},{"location":"docs/documentation/#app","title":"app","text":"PropertyValuecritical<code>95</code> operator<code>\"&lt;\"</code> warning<code>99</code>"},{"location":"docs/documentation/#controlplane","title":"controlPlane","text":"PropertyValuecritical<code>95</code> lowest<code>0</code> operator<code>\"&lt;\"</code> warning<code>99</code>"},{"location":"docs/documentation/#criticalpanel","title":"criticalPanel","text":"PropertyValuecritical<code>1</code> operator<code>\"&gt;=\"</code>"},{"location":"docs/documentation/#k8s_2","title":"k8s","text":"PropertyValuecritical<code>95</code> operator<code>\"&lt;\"</code> warning<code>99</code>"},{"location":"docs/documentation/#node","title":"node","text":"PropertyValuecritical<code>90</code> operator<code>\"&gt;=\"</code> warning<code>75</code>"},{"location":"docs/documentation/#warningpanel","title":"warningPanel","text":"PropertyValueoperator<code>\"&gt;=\"</code> warning<code>1</code>"},{"location":"docs/documentation/#templatebases","title":"templateBases","text":"PropertyValuebaseAlertbaseAlert basePolystatTemplatebasePolystatTemplate baseStatsTemplatebaseStatsTemplate baseTableTemplatebaseTableTemplate"},{"location":"docs/documentation/#basealert","title":"baseAlert","text":"PropertyValuecustomLables<code>{} </code> expr<code>\"\"</code> linkGetParams<code>\"\"</code> message<code>\"\"</code> name<code>\"error must be overwritten\"</code> thresholds<code>{} </code>"},{"location":"docs/documentation/#basepolystattemplate","title":"basePolystatTemplate","text":"PropertyValuedefault<code>true</code> enabled<code>true</code> panelpanel <p> panel </p> PropertyValuedatasource<code>\"$datasource\"</code> default_click_through<code>\"\"</code> description\"\"  expr<code>\"\"</code> fontAutoColor<code>false</code> fontColor<code>\"white\"</code> globalDecimals<code>null</code> global_thresholds<code>{} </code> global_unit_format<code>\"\"</code> gridPos<code>h: 6 w: 24 x: 0 y: 0 </code> hexagon_sort_by_direction<code>2</code> hexagon_sort_by_field<code>\"value\"</code> polygon_border_size<code>0</code> title<code>\"error must be overwritten\"</code> tooltip_timestamp_enabled<code>false</code> <p></p>"},{"location":"docs/documentation/#basestatstemplate","title":"baseStatsTemplate","text":"PropertyValuealert<code>{} </code> default<code>true</code> enabled<code>true</code> panelpanel <p> panel </p> PropertyValuecolorMode<code>\"background\"</code> dataLinks<code>[] </code> datasource<code>\"$datasource\"</code> decimals<code>null</code> description\"\"  expr<code>\"\"</code> graphMode<code>\"area\"</code> gridPos<code>h: 3 w: 6 x: error must be overwritten y: error must be overwritten </code> mappings<code>[] </code> thresholds<code>{} </code> title<code>\"error must be overwritten\"</code> unit<code>\"percent\"</code> <p></p>"},{"location":"docs/documentation/#basetabletemplate","title":"baseTableTemplate","text":"PropertyValuedefault<code>true</code> enabled<code>true</code> panelpanel <p> panel </p> PropertyValuedatasource<code>\"$datasource\"</code> description\"\"  expr<code>[] </code> gridPos<code>h: 19 w: 24 x: 0 y: 1 </code> sort<code>{} </code> styles<code>[] </code> title<code>\"error must be overwritten\"</code> transformations<code>[] </code> <p></p>"},{"location":"helpers/","title":"Helpers","text":"<p>A set of scripts and configuration files which helps to simplify local development.</p>"},{"location":"helpers/#local-development-using-kind-kubernetes-in-docker","title":"Local development using KinD (Kubernetes in Docker)","text":"<p>Prerequisites</p> <ul> <li>Kind</li> <li>Docker</li> <li>Helm3</li> <li>Kubectl</li> </ul> <p>Grafana dashboards and Prometheus alerts are stored in the jsonnet templates.</p> <p>Jsonnet templates are shipped in compressed form by the k8s configmap. Then the k8s configmap with compressed jsonnet is consumed by kubernetes-jsonnet-translator. kubernetes-jsonnet-translator translates jsonnet templates to the plain json and generates prometheus rule or grafana configmap k8s objects.</p> <p>If you want to test your local changes in local KinD k8s cluster use following steps:</p> <ol> <li>Create KinD cluster <pre><code>kind create cluster --config helpers/kind_cluster_config.yaml --image kindest/node:v1.25.11\n</code></pre></li> <li> <p>Install kubernetes-monitoring-stack (without dNation Kubernetes Monitoring dependency) K8s-m8g-stack is an umbrella helm chart which deploys Grafana, Loki and Prometheus Operator projects. <pre><code># Add dNation helm repository\nhelm repo add dnationcloud https://dnationcloud.github.io/helm-hub/\nhelm repo update\n\n# Install dNation Kubernetes Monitoring Stack without dNation Kubernetes Monitoring chart\nhelm install dnation-kubernetes-monitoring-stack dnationcloud/dnation-kubernetes-monitoring-stack -f https://raw.githubusercontent.com/dNationCloud/kubernetes-monitoring-stack/main/helpers/values-kind.yaml --set dnation-kubernetes-monitoring.enabled=false\n</code></pre></p> </li> <li> <p>Follow installation notes and use Port Forwarding if you want to access the Grafana server from outside your KinD cluster <pre><code>export POD_NAME=$(kubectl get pods --namespace default -l \"app.kubernetes.io/name=grafana,app.kubernetes.io/instance=dnation-kubernetes-monitoring-stack\" -o jsonpath=\"{.items[0].metadata.name}\")\nkubectl --namespace default port-forward $POD_NAME 3000\n</code></pre></p> </li> <li> <p>Package jsonnet templates <pre><code>make jsonnet-package\n</code></pre></p> </li> <li>Deploy dNation Kubernetes Monitoring with your changes <pre><code># Update K8s monitoring chart dependencies\nhelm dependency update chart\n# K8s monitoring only (default)\nhelm install dnation-kubernetes-monitoring chart --set releaseOverride=dnation-kubernetes-monitoring-stack\n# Cluster monitoring example with custom dashboard templates\nhelm install dnation-kubernetes-monitoring chart --set releaseOverride=dnation-kubernetes-monitoring-stack -f helpers/values-cluster-elk.yaml\n# Host monitoring example\nhelm install dnation-kubernetes-monitoring chart --set releaseOverride=dnation-kubernetes-monitoring-stack -f helpers/values-host.yaml\n# Multi-cluster monitoring example\nhelm install dnation-kubernetes-monitoring chart --set releaseOverride=dnation-kubernetes-monitoring-stack -f helpers/values-multicluster.yaml\n</code></pre></li> </ol> <p>If you want to run jsonnet formatter or linter use following: <pre><code># Format jsonnet files\nmake jsonnet-fmt\n# Lint jsonnet files\nmake jsonnet-lint\n</code></pre> If you want to generate plain json grafana dashboards or prometheus rules use following: <pre><code># Build json grafana dashboards\nmake json-dashboards\n# Build json prometheus rules\nmake json-rules\n</code></pre> If you want to run helm linter use following: <pre><code># Lint helm chart\nmake helm-lint\n</code></pre></p>"},{"location":"helpers/FAQ/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"helpers/FAQ/#how-to-interpret-displayed-monitoring-values-across-different-monitoring-layers","title":"How to interpret displayed monitoring values across different monitoring layers?","text":""},{"location":"helpers/FAQ/#monitoring-layer-0","title":"Monitoring Layer 0","text":""},{"location":"helpers/FAQ/#kubernetes-monitoring","title":"Kubernetes monitoring","text":"<p>Kubernetes cluster health is simply represented by the single state panel. State panel aggregates alerts from the  underlying layer of kubernetes monitoring. The healthy status is represented by the green state panel with 'OK' label. It is displayed if the k8s cluster meets all the defined thresholds for healthy status. When some threshold is crossed and this state  persists for 5 minutes (default), relevant alert is triggered and highlighted. The orange state panel  with <code>Warning</code> label is displayed in case of warning alert. Red state panel with  <code>Critical</code> label is displayed in case of critical alert. We have implemented intuitive green, orange and red color indicators that are signalizing if your action is needed or if everything is OK. If you want to see more information about your k8s cluster, just drill down by left-clicking on the relevant state panel. As of now, multi-cluster monitoring support is available.</p> <ul> <li>If you are interested in the k8s cluster monitoring see How to set up k8s cluster monitoring? section.</li> <li>If you are interested in the k8s multi-cluster monitoring see How to set up k8s multi-cluster monitoring? section.</li> </ul>"},{"location":"helpers/FAQ/#host-monitoring","title":"Host monitoring","text":"<p>Host monitoring integration allows you to monitor your hosts infrastructure within our kubernetes based,  stable and highly available monitoring. Hosts state panel functions on the same principles as k8s cluster state panel. Multi host  monitoring is supported. - If you are interested in the host monitoring see How to set up host monitoring? section.</p>"},{"location":"helpers/FAQ/#k8s-monitoring-layer-1","title":"K8s monitoring Layer 1","text":"<p> The first layer of k8s monitoring consists of state panels that visualize the current state of your k8s cluster. The state panels are separated into several sections: - Alerts - Overview - Control Plane Components Health - Node Metrics (including Master) - Applications (optional)</p> <p>When a failed condition of monitored k8s element occurs the state panel shows lowered percentage value on health indicator. If the state of health is too  low and the percentage value reached warning or even critical threshold, corresponding state panel changes its color. Intuitive green, orange and red color principle is used. When failed state lasts longer than 5 minutes (default) then  the relevant alert is triggered and highlighted in alert panel. Also the panel representing the overall health of the k8s cluster in the monitoring layer 0 changes accordingly. The first layer is the source of all aggregated k8s cluster alerts triggered by dNation monitoring.</p>"},{"location":"helpers/FAQ/#alerts","title":"Alerts","text":"<p>The upper section shows the amount of triggered critical and warning alerts. If you want to see detailed list of  triggered alerts simply apply the drill down principle.</p>"},{"location":"helpers/FAQ/#overview","title":"Overview","text":"<p>The overview section allows you to monitor the health status of k8s nodes, workloads (deployments, stateful sets, daemon sets, pods, containers and more) and persistent volumes. Each state panel contains important information of monitored k8s element, e.g. single node health state panel gives you an insight on whether the k8s nodes are able to schedule resources or if they are under disk, memory or PID pressure.</p>"},{"location":"helpers/FAQ/#control-plane-components","title":"Control Plane Components","text":"<p>Monitoring of k8s cluster control plane components (api server, controller manager, etcd database, kubelet, proxy and scheduler)  is located in separate section. If you want to check the work queue rate of controller manager or scheduler latency, the Control Plane Components section is the section you are looking for.</p>"},{"location":"helpers/FAQ/#node-metrics-including-master","title":"Node Metrics (including Master)","text":"<p>Measuring k8s nodes system metrics is important in ensuring k8s cluster availability. Node Metrics section gives you a clear overview of cluster's CPU, memory, disk and network utilization. Each system metric is visualized in several state panels such as overall (average) utilization panel, the most utilized cluster node panel and information panels which show used and total state of system metrics. It is always useful to know overall cluster utilization, but it is also important to know when one node is utilized more than other nodes which may indicates that your k8s cluster doesn't work properly. If you want to drill down for further investigation of your k8s node you can select between <code>System Overview</code> or <code>K8s Overview</code> buttons. <code>System Overview</code> shows CPU, memory, disk and network utilization per k8s cluster node in greater detail. <code>K8s Overview</code> shows systems resource usage in k8s oriented manner, meaning that you can filter particular k8s workload per k8s cluster node or see information about CPU and memory requests and limits.</p>"},{"location":"helpers/FAQ/#applications","title":"Applications","text":"<p>In order to thoroughly understand application health, we created custom dashboards which help us to properly understand and diagnose application workloads in k8s cluster. As of today we have designed several dashboards for well known and widely used  frameworks such as java actuator, python flask, nginx ingress controller and more. Layer 1 state panels aggregate  important information of monitored application. Green, orange and red color principle informs us if there is action needed and drill down principle can be used to access verbose and detailed application dashboard. </p> <ul> <li>If you want to customize your L1 layer see How to customize my k8s monitoring? section.</li> <li>If you are interested in the k8s application monitoring see How to set up k8s application monitoring? section.</li> </ul>"},{"location":"helpers/FAQ/#k8s-monitoring-lower-layers","title":"K8s monitoring lower layers","text":"<p>If you want to know details on why is particular stat panel in upper layer green, orange or red, just drill down. Look at some examples from layer 2 and layer 3 of k8s monitoring:</p> <ul> <li>K8s monitoring Layer 2 example</li> </ul> Containers Node Disks Application <ul> <li>K8s monitoring Layer 3 example</li> </ul> Containers Nodes"},{"location":"helpers/FAQ/#host-monitoring-layer-1","title":"Host monitoring Layer 1","text":"<p> The first layer of host monitoring consists of state panels that visualize the current state of your host. The state panels are separated into several sections: - Alerts - Host - Applications (optional)</p> <p>When a failed condition of monitored host element occurs the state panel shows lowered percentage value on health indicator. If the state of health is too low and the percentage value reached warning or even critical threshold, corresponding state panel changes its color. Intuitive green, orange and red color principle is used. When failed state lasts longer than 5 minutes (default) then the relevant alert is triggered and highlighted in alert panel. Also the panel representing the overall health of the host in the monitoring layer 0 changes accordingly. The first layer is the source of all aggregated hosts alerts triggered by dNation monitoring.</p>"},{"location":"helpers/FAQ/#alerts_1","title":"Alerts","text":"<p>The upper section shows the amount of triggered critical and warning alerts. If you want to see detailed list of  triggered alerts simply apply the drill down principle.</p>"},{"location":"helpers/FAQ/#host","title":"Host","text":"<p>Host section gives you clear overview of host's CPU, memory, disk and network utilization. Each system metric is visualized in several state panels. The main host overall utilization panel and information panels show used and total state of system metric.</p>"},{"location":"helpers/FAQ/#applications_1","title":"Applications","text":"<p>In order to thoroughly understand application health, we created custom dashboards which help us to properly understand and diagnose host applications. As of today, we have designed several dashboards such as cadvisor. Layer 1 state panels aggregate important information of monitored application. Green, orange and red color principle informs us if there is some action needed and drill down principle can be used to access verbose and detailed application dashboard.</p> <ul> <li>If you want to customize your L1 layer by custom host monitoring template definition, see How to customize my host monitoring? section.</li> <li>If you are interested in the host application monitoring, see How to set up host application monitoring? section.</li> </ul>"},{"location":"helpers/FAQ/#host-monitoring-lower-layers","title":"Host monitoring lower layers","text":"<p>If you want to know details why is some stats panel in upper layer green, orange or red, just drill down and click it. See some examples from layer 2 of host monitoring:</p> Host Detail Application"},{"location":"helpers/FAQ/#how-to-set-up-k8s-cluster-monitoring","title":"How to set up k8s cluster monitoring?","text":""},{"location":"helpers/FAQ/#prerequisites","title":"Prerequisites","text":"<p>Install dNation k8s monitoring on k8s cluster. See installation steps here. </p>"},{"location":"helpers/FAQ/#set-up","title":"Set up","text":"<p>K8s cluster monitoring is enabled by default. See the docs: <pre><code>clusterMonitoring:\n  enabled: true\n  clusters:\n  - name: K8sCluster\n    label: observer-cluster  # The label should be the same as the external_label `cluster` from prometheus\n    description: 'Kubernetes cluster monitoring'\n    apps: []\n</code></pre> It means that your k8s cluster is being monitored right after installation of dNation k8s monitoring. If you want to customize k8s cluster monitoring see How to customize my k8s monitoring? section.</p>"},{"location":"helpers/FAQ/#how-to-customize-my-k8s-monitoring","title":"How to customize my k8s monitoring?","text":"<p>We understand that each k8s cluster may contain various workloads or implement various scaling strategies. We tried to do our best and set up suitable defaults based on our production environment experiences, but we know that  isn't possible cover the variety of k8s cluster configurations. To tackle this problem, we implemented template logic that allows you to fully customize the default state panels or alerts. You can also create your own to fulfill your k8s cluster monitoring requirements. Currently only first layer is customizable, however, the templating of other layers is under development. For full list of k8s templates see the docs.</p> <p>If you want to customize default layer 1 template in k8s monitoring just create a simple yaml file: <pre><code>templates:\n  k8s:\n    # Override stats panel title and warning thresholds for the etcd health panel\n    etcdHealth:\n      panel:\n        title: \"Custom Title\"\n        thresholds:\n          warning: 96\n      alert:\n        thresholds:\n          warning: 96\n</code></pre> Each state panel that can be modified contains a template name in its description for easy navigation:</p> <p></p> <p>Finally, update your k8s monitoring deployment and override the default monitoring configuration: <pre><code>helm upgrade [RELEASE] [CHART] -f override.yaml\n</code></pre> If you want to create your own custom template see full examples in the <code>helpers</code> directory.</p>"},{"location":"helpers/FAQ/#how-to-set-up-k8s-application-monitoring","title":"How to set up k8s application monitoring?","text":""},{"location":"helpers/FAQ/#prerequisites_1","title":"Prerequisites","text":"<p>Enable or install metrics exporter in your k8s application.</p>"},{"location":"helpers/FAQ/#set-up_1","title":"Set up","text":"<p>K8s application monitoring is disabled by default. See the docs. To enable it just create application monitoring definition as follows: <pre><code>clusterMonitoring:\n  enabled: true\n  clusters:\n  - name: K8sCluster\n    label: observer-cluster  # The label should be the same as the external_label `cluster` from prometheus\n    description: 'Kubernetes cluster with application monitoring'\n    apps:\n    - name: app-example\n      description: Example of App Monitoring\n      jobName: flask-app  # The job name should be the same as the name which will be retrieved from the `jobLabel`, see the `serviceMonitor` section\n      templates:\n        javaActuator:  # Application Exporter template\n          enabled: true\n      serviceMonitor:\n        jobLabel: app  # The label to use to retrieve the job name from.\n        namespaceSelector:  # Namespaces to transfer from the kubernetes service to the target\n          matchNames:\n          - default\n        selector:  # Label selector for services to which this ServiceMonitor applies\n          matchLabels:\n            app: flask-app\n        # Endpoints of the selected service to be monitored\n        # ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint\n        endpoints:\n        - targetPort: metrics  # Name or number of the endpoint's target port\n          path: /metrics  # HTTP path to scrape for metrics\n</code></pre></p> <p>Application monitoring definition contains two main sections: <code>template</code> and <code>serviceMonitor</code> or <code>podMonitor</code> respectively. The <code>template</code> section defines which template and pre-defined application dashboard will be used. For full list of pre-defined k8s application templates see the docs. Application monitoring metrics endpoint is auto-discovered by service monitor  or by pod monitor CRDs. See the documentation of CRDs to ensure that your application metrics endpoint will be discovered as you want or find some  examples in <code>helpers</code> directory.</p> <p>Finally, update your k8s monitoring deployment and apply the application monitoring configuration: <pre><code>helm upgrade [RELEASE] [CHART] -f apps.yaml\n</code></pre> - If you want to customize the default application template see How to customize my k8s monitoring? section.</p>"},{"location":"helpers/FAQ/#how-to-set-up-host-monitoring","title":"How to set up host monitoring?","text":""},{"location":"helpers/FAQ/#prerequisites_2","title":"Prerequisites","text":"<p>Enable or install node exporter in your host. You can use <code>helpers/node_exporter.sh</code> installation script.</p>"},{"location":"helpers/FAQ/#set-up_2","title":"Set up","text":"<p>Host monitoring is disabled by default. See the docs. To enable it just create host monitoring definition as follows: <pre><code>hostMonitoring:\n  enabled: true\n  hosts:\n  - name: host-01\n    description: Host 01\n    jobName: host-01\n    host:\n      address: 1.1.1.1  # Host IP address\n    serviceMonitor:\n      endpoints:\n      - port: 9100  # Node exporter port\n        path: /metrics  # Node exporter metrics path\n</code></pre> Host monitoring definition contains two main sections: <code>host</code> and <code>serviceMonitor</code>. The <code>host</code> section simply defines the host IP address. The <code>serviceMonitor</code> defines service monitor CRD endpoint i.e. the host's node exporter port and path. Lot of service monitor parameters are pre-configured to simplify host monitoring configuration. If you are interested how or you want to  override some of these parameters see the <code>chart/templates/hosts</code> directory. </p> <p>Finally, update your k8s monitoring deployment and apply the host monitoring configuration: <pre><code>helm upgrade [RELEASE] [CHART] -f host.yaml\n</code></pre></p>"},{"location":"helpers/FAQ/#how-to-customize-my-host-monitoring","title":"How to customize my host monitoring?","text":"<p>To cover variety of host configurations we implemented the template logic in the host monitoring as well. Templates allow you to fully customize the default state panels or alerts. You can also create your own to fulfill your host monitoring requirements. Currently, layer 1 customization is implemented. For full list of host templates see the docs.</p> <p>If you want to customize default layer 1 template in host monitoring just create a simple yaml file: <pre><code>templates:\n  host:\n    # Override warning thresholds for the CPU utilization panel\n    overallUtilizationCPU:\n      panel:\n        thresholds:\n          warning: 50\n      alert:\n        thresholds:\n          warning: 50\n</code></pre> Each state panel that can be modified contains a template name in its description for easy navigation:</p> <p></p> <p>Finally, update your k8s monitoring deployment and override the default monitoring configuration: <pre><code>helm upgrade [RELEASE] [CHART] -f override.yaml\n</code></pre> If you want to create your own custom template see full examples in the <code>helpers</code> directory.</p>"},{"location":"helpers/FAQ/#how-to-set-up-host-application-monitoring","title":"How to set up host application monitoring?","text":""},{"location":"helpers/FAQ/#prerequisites_3","title":"Prerequisites","text":"<p>Enable or install metrics exporter in your host application.</p>"},{"location":"helpers/FAQ/#set-up_3","title":"Set up","text":"<p>Hosts application monitoring is disabled by default. See the docs. To enable it just create application monitoring definition as follows: <pre><code>hostMonitoring:\n  enabled: true\n  hosts:\n  - name: host-01\n    description: 'Host 01 with application monitoring'\n    host:\n      address: 1.2.3.4\n    apps:\n    - name: host-01-docker\n      description: Host 01 Docker Containers\n      jobName: host-01-docker\n      templates:\n        cAdvisor:  # Application Exporter template\n          enable: true\n      serviceMonitor:\n        endpoints:\n        - port: 9101  # Application exporter port\n          path: /metrics  # Application exporter metrics path\n</code></pre></p> <p>Application monitoring definition contains two main sections: <code>template</code> and <code>serviceMonitor</code>. The <code>template</code> section defines which template and pre-defined application dashboard will be used. For full list of pre-defined host application templates see the docs. The <code>serviceMonitor</code> defines service monitor CRD endpoint, i.e. the application's exporter port and path. Lot of service monitor parameters are pre-configured to simplify application monitoring configuration. If you are curious how or you want to  override some of these parameters see the <code>chart/templates/hosts</code> directory or find some examples in <code>helpers</code> directory.</p> <p>Finally, update your k8s monitoring deployment and apply the application monitoring configuration: <pre><code>helm upgrade [RELEASE] [CHART] -f apps.yaml\n</code></pre> - If you want to customize the default application template see the How to customize my host monitoring? section.</p>"},{"location":"helpers/FAQ/#why-l2-table-item-has-different-background-color-as-corresponding-l1-stat-panel","title":"Why L2 table item has different background color as corresponding L1 stat panel?","text":"<p>If you customized your k8s monitoring, you can see that some table items on L2 layer dashboard may have different background color as corresponding L1 stat panel.</p> <p>Example: - Define custom L1 PVC utilization panel with custom thresholds for ELK PVCs  - If you drill down, you can see that corresponding PVC capacity is in Critical state (orange background color) </p> <p>Currently only first layer is customizable, which caused this unexpected behaviour. Templating of other layers is under development and is planned in v1.1.x release.</p>"},{"location":"helpers/FAQ/#kubernetes-monitoring-shows-or-0-state-for-some-control-plane-components-are-control-plane-components-working-correctly","title":"Kubernetes Monitoring shows <code>-</code> OR <code>0%</code> state for some control plane components. Are control plane components working correctly?","text":"<p>Control plane components work probably well, but their metrics server might be disabled, misconfigured or may not be present at all. For example, if is used OVNKubernetes CNI <code>kube-proxy</code> doesn't exist here. You should want  to check address bindings of control plane components' metrics as follows:</p> <p>The metrics of <code>etcd</code> and <code>kube-proxy</code> control plane components are by default bound to the localhost that prometheus instances cannot access. Also make sure metrics of <code>scheduler</code> and <code>controller-manager</code> control plane components don't have the same address binding if you want to collect them.</p> <p>Edit and use <code>kubeadm_init.yaml</code> file to configure <code>kubeadm init</code> in case of fresh K8s deployment.</p> <pre><code>kubeadm init --config=helpers/kubeadm_init.yaml\n</code></pre> <p>Manual setup in case of already running K8s deployment.</p> <ul> <li> <p>Setup <code>etcd</code> metrics bind address     <pre><code># On k8s master node\ncd /etc/kubernetes/manifests/\nsudo vim etcd.yaml\n# Add listen-metrics-urls as etcd command option\n...\n- --listen-metrics-urls=http://0.0.0.0:2381\n...\n</code></pre></p> </li> <li> <p>Setup <code>kube-proxy</code> metrics bind address</p> <p>Edit kube-proxy daemon set <pre><code>kubectl edit ds kube-proxy -n kube-system\n...containers:\n      - command:\n        - /usr/local/bin/kube-proxy\n        - --config=/var/lib/kube-proxy/config.conf\n        - --hostname-override=$(NODE_NAME)\n        - --metrics-bind-address=0.0.0.0  # Add metrics-bind-address line\n</code></pre> Edit kube-proxy config map <pre><code>kubectl -n kube-system edit cm kube-proxy\n...\n    kind: KubeProxyConfiguration\n    metricsBindAddress: \"0.0.0.0:10249\" # Add metrics-bind-address host:port\n    mode: \"\"\n</code></pre> Delete the kube-proxy pods and reapply the new configuration <pre><code>kubectl -n kube-system delete po -l k8s-app=kube-proxy\n</code></pre></p> </li> <li> <p>Setup <code>scheduler</code> metrics bind address     <pre><code># On k8s master node\ncd /etc/kubernetes/manifests/\nsudo vim kube-scheduler.yaml\n# Edit bind-address and port command options\n...\n- --bind-address=0.0.0.0\n- --secure-port=10259\n...\n</code></pre></p> </li> <li> <p>Setup <code>controller-manager</code> metrics bind address     <pre><code># On k8s master node\ncd /etc/kubernetes/manifests/\nsudo vim kube-controller-manager.yaml\n# Edit bind-address and port command options\n...\n- --bind-address=0.0.0.0\n- --secure-port=10257\n...\n</code></pre></p> </li> </ul> <p>You should also check: * TLS configuration of prometheus components responsible for scraping <code>controller-manager</code> and <code>scheduler</code>. If you don't want to set up TLS, you can skip validation as shown here.</p> <ul> <li>Authorization to access <code>controller-manager</code> and <code>scheduler</code>. You can skip authorization for some endpoints    by setting <code>--authorization-always-allow-paths: \"/healthz,/readyz,/livez,/metrics\"</code> in <code>kubeadm_init.yaml</code> (see example for kind cluster) or    manually in already running K8s deployment by following same steps as above when setting metrics bind address.</li> </ul>"},{"location":"helpers/FAQ/#how-to-set-up-k8s-multi-cluster-monitoring","title":"How to set up k8s multi-cluster monitoring?","text":""},{"location":"helpers/FAQ/#prerequisites_4","title":"Prerequisites","text":"<p>Install dNation k8s monitoring on k8s cluster. See installation steps here.</p>"},{"location":"helpers/FAQ/#set-up_4","title":"Set up","text":"<p>Multi-cluster monitoring is supported by default. All you need to do is just to install dNation Kubernetes Monitoring with custom values as shown in example here. <pre><code>clusterMonitoring:\n  enabled: true\n  clusters:\n  - name: Observer\n    label: observer-cluster\n    description: 'Kubernetes cluster with application monitoring'\n    apps: []\n  - name: Workload\n    label: workload-cluster\n    description: 'Kubernetes cluster with application monitoring'\n    apps: []\n</code></pre></p> <p>Do not forget to set the correct labels for your clusters!</p>"},{"location":"helpers/ci_cd_image/","title":"Jsonnet","text":"<p>A simple Docker image includes jsonnet, jsonnetfmt, jsonnet-lint, yq and jsonnet lib like grafonnet-lib and grafonnet-polystat-panel. Docker image was built for the CI/CD purposes or to avoid having to install jsonnet tools on your computer (keep it in docker).</p>"},{"location":"helpers/ci_cd_image/#usage","title":"Usage","text":"<pre><code># Jsonnet\ndocker run --rm -it -v `pwd`:/src dnationcloud/jsonnet:&lt;tagname&gt; jsonnet -h\n# Jsonnet Formater\ndocker run --rm -it -v `pwd`:/src dnationcloud/jsonnet:&lt;tagname&gt; jsonnetfmt -h\n# Jsonnet Linter\ndocker run --rm -it -v `pwd`:/src dnationcloud/jsonnet:&lt;tagname&gt; jsonnet-lint -h\n# YQ\ndocker run --rm -it -v `pwd`:/src dnationcloud/jsonnet:&lt;tagname&gt; yq -h\n</code></pre> <p>Inspect versions <pre><code>docker inspect --format '{{ index .Config.Labels }}' dnationcloud/jsonnet:&lt;tagname&gt;\n</code></pre></p>"}]}